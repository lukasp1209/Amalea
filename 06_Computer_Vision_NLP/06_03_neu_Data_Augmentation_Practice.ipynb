{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06_03_neu: Data Augmentation Practice (CPU)\n",
    "\n",
    "## Einführung\n",
    "Augmentation als Gegenmittel zu Overfitting: Vergleich von Keras-Preprocessing-Layern mit optionalem Albumentations-Stack, trainiert auf einem kleinen CIFAR-Subset mit/ohne Augmentation.\n",
    "\n",
    "**Lernziele**\n",
    "- Overfitting auf kleinem Datensatz erkennen\n",
    "- Keras-Augmentationspipeline konfigurieren und im `tf.data`-Stream nutzen\n",
    "- (Optional) Albumentations als Referenz ausprobieren\n",
    "- Trainings- und Test-Accuracy mit/ohne Augmentation vergleichen\n",
    "- Laufzeit steuern: Anzahl Samples, Epochen und Batchgröße anpassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup & Data (tiny subset)\n",
    "import os, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "np.random.seed(42); random.seed(42); tf.random.set_seed(42)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "keep = 3000\n",
    "x_train, y_train = x_train[:keep], y_train[:keep]\n",
    "x_test, y_test = x_test[:800], y_test[:800]\n",
    "class_names = [\"airplane\",\"auto\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "\n",
    "x_train = x_train.astype(\"float32\")/255.0\n",
    "x_test = x_test.astype(\"float32\")/255.0\n",
    "\n",
    "print(\"Train\", x_train.shape, \"Test\", x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual sanity check\n",
    "fig, axes = plt.subplots(2,5, figsize=(10,4))\n",
    "for ax, img, label in zip(axes.flat, x_train[:10], y_train[:10]):\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(class_names[int(label)])\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras preprocessing pipeline\n",
    "augment_layers = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "# Albumentations alternative (optional)\n",
    "try:\n",
    "    import albumentations as A\n",
    "    alb_aug = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(0.1,0.1,p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10, p=0.5),\n",
    "    ])\n",
    "except ImportError:\n",
    "    alb_aug = None\n",
    "    print(\"Albumentations nicht installiert - Keras-Only Demo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare augmentations\n",
    "sample = x_train[0]\n",
    "\n",
    "fig, axes = plt.subplots(1,4, figsize=(12,3))\n",
    "axes[0].imshow(sample); axes[0].set_title(\"Original\"); axes[0].axis(\"off\")\n",
    "\n",
    "keras_aug = augment_layers(tf.convert_to_tensor(sample[None,:,:,:])).numpy()[0]\n",
    "axes[1].imshow(keras_aug); axes[1].set_title(\"Keras aug\"); axes[1].axis(\"off\")\n",
    "\n",
    "if alb_aug:\n",
    "    alb_img = alb_aug(image=(sample*255).astype(np.uint8))['image']\n",
    "    axes[2].imshow(alb_img); axes[2].set_title(\"Albumentations\"); axes[2].axis(\"off\")\n",
    "else:\n",
    "    axes[2].axis(\"off\"); axes[2].set_title(\"Albumentations n/a\")\n",
    "\n",
    "# stronger Keras example\n",
    "keras_aug2 = augment_layers(tf.convert_to_tensor(sample[None,:,:,:])).numpy()[0]\n",
    "axes[3].imshow(keras_aug2); axes[3].set_title(\"Keras aug 2\")\n",
    "axes[3].axis(\"off\")\n",
    "\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-CNN helper\n",
    "\n",
    "def make_model():\n",
    "    return keras.Sequential([\n",
    "        layers.Input(shape=(32,32,3)),\n",
    "        layers.Conv2D(32,3,activation='relu',padding='same'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64,3,activation='relu',padding='same'),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(64,activation='relu'),\n",
    "        layers.Dense(10,activation='softmax'),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b7e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline (no aug)\n",
    "baseline = make_model()\n",
    "baseline.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "h_baseline = baseline.fit(\n",
    "    x_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=3,\n",
    "    batch_size=128,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "# Train with Keras aug pipeline\n",
    "augmented = make_model()\n",
    "augmented.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "data_aug = augment_layers\n",
    "\n",
    "aug_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    .shuffle(keep, seed=42)\n",
    "    .batch(128)\n",
    "    .map(lambda x,y: (data_aug(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "h_aug = augmented.fit(\n",
    "    aug_ds,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=3,\n",
    "    verbose=2,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval comparison\n",
    "bl_acc = baseline.evaluate(x_test, y_test, verbose=0)[1]\n",
    "aug_acc = augmented.evaluate(x_test, y_test, verbose=0)[1]\n",
    "print(f\"Baseline acc: {bl_acc:.3f} vs Aug acc: {aug_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipps\n",
    "- Für noch schnellere Läufe: keep=1500, epochs=2.\n",
    "- Albumentations nur optional; Kernpipeline ist Keras-preprocessing.\n",
    "- Augmentation im tf.data-Stream belassen, um RAM zu sparen."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
