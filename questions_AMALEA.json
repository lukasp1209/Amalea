[
  {
    "frage": "1. Was ist der Hauptzweck von Docker in einem Data-Science-Projekt?",
    "optionen": [
      "Um die Performance von Python-Skripten zu beschleunigen.",
      "Um eine reproduzierbare und isolierte Umgebung für die Software zu schaffen.",
      "Um Jupyter Notebooks direkt in der Cloud auszuführen.",
      "Um die Größe von Datensätzen zu reduzieren."
    ],
    "loesung": 1,
    "erklaerung": "Docker packt eine Anwendung und ihre Abhängigkeiten in einen Container, der überall gleich läuft. Das löst das 'Bei mir funktioniert es aber'-Problem und sorgt für Reproduzierbarkeit.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "2. Welcher Befehl wird verwendet, um eine Streamlit-App zu starten?",
    "optionen": [
      "python run app.py",
      "streamlit start app.py",
      "streamlit run app.py",
      "start streamlit app.py"
    ],
    "loesung": 2,
    "erklaerung": "Der Befehl 'streamlit run <dateiname>.py' startet den Streamlit-Server und öffnet die App im Browser.",
    "gewichtung": 1,
    "thema": "Streamlit"
  },
  {
    "frage": "3. Was ist ein Pandas DataFrame?",
    "optionen": [
      "Eine ein-dimensionale Datenstruktur für numerische Daten.",
      "Eine zweidimensionale, tabellarische Datenstruktur mit Spalten und Zeilen.",
      "Eine Bibliothek zur Erstellung von interaktiven Diagrammen.",
      "Ein Machine-Learning-Modell zur Klassifikation."
    ],
    "loesung": 1,
    "erklaerung": "Ein Pandas DataFrame ist die zentrale Datenstruktur in Pandas und ähnelt einer Excel-Tabelle oder einer SQL-Tabelle. Sie ist für die Handhabung und Analyse von strukturierten Daten optimiert.",
    "gewichtung": 1,
    "thema": "Pandas"
  },
  {
    "frage": "4. Was ist der Hauptunterschied zwischen Supervised und Unsupervised Learning?",
    "optionen": [
      "Supervised Learning benötigt mehr Rechenleistung.",
      "Unsupervised Learning wird nur für Textdaten verwendet.",
      "Supervised Learning verwendet gelabelte Daten (Input und Output), Unsupervised Learning nicht.",
      "Unsupervised Learning ist immer genauer als Supervised Learning."
    ],
    "loesung": 2,
    "erklaerung": "Der Kernunterschied ist das Vorhandensein von 'Antworten' in den Trainingsdaten. Supervised Learning lernt von Beispielen mit bekannten Ergebnissen (Labels), während Unsupervised Learning Muster in ungelabelten Daten sucht.",
    "gewichtung": 2,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "5. Welcher Algorithmus gehört zum Unsupervised Learning?",
    "optionen": [
      "Decision Tree",
      "K-Nearest Neighbors (KNN)",
      "K-Means Clustering",
      "Logistic Regression"
    ],
    "loesung": 2,
    "erklaerung": "K-Means ist ein Clustering-Algorithmus, der versucht, Datenpunkte ohne vordefinierte Labels in 'k' Gruppen (Cluster) einzuteilen. Decision Tree, KNN und Logistic Regression sind Supervised-Learning-Algorithmen.",
    "gewichtung": 2,
    "thema": "Machine Learning Algorithmen"
  },
  {
    "frage": "6. Was ist der Zweck der 'Elbow-Methode'?",
    "optionen": [
      "Die optimale Anzahl der 'Nachbarn' (k) für KNN zu finden.",
      "Die optimale Anzahl der 'Cluster' (k) für K-Means zu finden.",
      "Die optimale Tiefe eines Decision Trees zu bestimmen.",
      "Die optimale Lernrate für ein Neuronales Netz zu finden."
    ],
    "loesung": 1,
    "erklaerung": "Die Elbow-Methode plottet die 'Inertia' (Summe der quadrierten Abstände zu den Cluster-Zentren) für verschiedene k-Werte. Der 'Ellenbogen' in der Kurve deutet auf ein gutes 'k' hin.",
    "gewichtung": 3,
    "thema": "Machine Learning Algorithmen"
  },
  {
    "frage": "7. Was ist die Hauptfunktion einer Aktivierungsfunktion in einem Neuronalen Netz?",
    "optionen": [
      "Sie normalisiert die Eingabedaten.",
      "Sie führt Nichtlinearität in das Modell ein.",
      "Sie berechnet den Fehler des Modells.",
      "Sie initialisiert die Gewichte des Netzwerks."
    ],
    "loesung": 1,
    "erklaerung": "Ohne nichtlineare Aktivierungsfunktionen wäre ein Neuronales Netz nur eine Kaskade von linearen Operationen, was es auf die Modellierung linearer Zusammenhänge beschränken würde. Die Nichtlinearität ermöglicht das Lernen komplexer Muster.",
    "gewichtung": 2,
    "thema": "Neuronale Netze"
  },
  {
    "frage": "8. Welche Aktivierungsfunktion wird typischerweise in der Ausgabeschicht eines Neuronalen Netzes für eine Multi-Klassen-Klassifikation verwendet?",
    "optionen": [
      "ReLU",
      "Sigmoid",
      "Tanh",
      "Softmax"
    ],
    "loesung": 3,
    "erklaerung": "Die Softmax-Funktion wandelt die rohen Ausgabe-Scores (Logits) des Netzes in eine Wahrscheinlichkeitsverteilung über alle Klassen um, wobei die Summe der Wahrscheinlichkeiten 1 ergibt.",
    "gewichtung": 2,
    "thema": "Neuronale Netze"
  },
  {
    "frage": "9. Was ist der Hauptvorteil von Convolutional Neural Networks (CNNs) gegenüber normalen Neuronalen Netzen bei der Bildverarbeitung?",
    "optionen": [
      "Sie sind schneller zu trainieren, da sie weniger Daten benötigen.",
      "Sie nutzen 'Weight Sharing' und 'Local Connectivity', um die Anzahl der Parameter drastisch zu reduzieren.",
      "Sie können nur mit Graustufenbildern arbeiten.",
      "Sie benötigen keine Aktivierungsfunktionen."
    ],
    "loesung": 1,
    "erklaerung": "CNNs verwenden Filter (Kernel), deren Gewichte über das gesamte Bild geteilt werden. Das macht sie extrem parameter-effizient und gut darin, lokale räumliche Muster zu erkennen, was für Bilder ideal ist.",
    "gewichtung": 3,
    "thema": "Computer Vision"
  },
  {
    "frage": "10. Was ist Data Augmentation?",
    "optionen": [
      "Das manuelle Hinzufügen von neuen, gelabelten Daten zum Trainingsset.",
      "Das künstliche Erzeugen neuer Trainingsdaten durch Transformationen der bestehenden Daten (z.B. Drehen, Spiegeln).",
      "Eine Methode zur Beschleunigung des Modell-Trainings.",
      "Das Entfernen von fehlerhaften Daten aus dem Datensatz."
    ],
    "loesung": 1,
    "erklaerung": "Data Augmentation ist eine Technik, um Overfitting zu reduzieren, indem man dem Modell zur Trainingszeit leicht veränderte Versionen der Bilder zeigt. Dadurch lernt das Modell, robustere und allgemeinere Merkmale zu erkennen.",
    "gewichtung": 2,
    "thema": "Computer Vision"
  },
  {
    "frage": "11. Was versteht man unter Transfer Learning?",
    "optionen": [
      "Das Trainieren eines Modells von Grund auf mit einem sehr großen Datensatz.",
      "Die Verwendung eines auf einer großen Aufgabe vortrainierten Modells als Ausgangspunkt für eine neue, spezifischere Aufgabe.",
      "Die Übertragung eines Modells von einer Programmiersprache in eine andere.",
      "Das Trainieren mehrerer Modelle auf verschiedenen Teilen eines Datensatzes."
    ],
    "loesung": 1,
    "erklaerung": "Beim Transfer Learning nutzt man das 'Wissen' (die gelernten Features) eines Modells, das auf einem riesigen Datensatz (z.B. ImageNet) trainiert wurde, und passt es mit einem kleineren, aufgabenspezifischen Datensatz an. Dies spart enorm viel Zeit und Daten.",
    "gewichtung": 3,
    "thema": "Deep Learning"
  },
  {
    "frage": "12. Was ist der Zweck des QUA³CK-Prozessmodells?",
    "optionen": [
      "Es ist ein spezifischer Machine-Learning-Algorithmus.",
      "Es ist ein Framework zur Beschleunigung von Python-Code.",
      "Es bietet eine strukturierte Vorgehensweise für Data-Science-Projekte von der Fragestellung bis zum Wissenstransfer.",
      "Es ist eine Bibliothek zur Datenvisualisierung."
    ],
    "loesung": 2,
    "erklaerung": "QUA³CK ist ein am KIT entwickeltes Prozessmodell, das die Phasen Question, Understanding, die A³-Schleife (Algorithm, Adapting, Adjusting), Conclude und Knowledge Transfer umfasst, um ML-Projekte systematisch zu bearbeiten.",
    "gewichtung": 2,
    "thema": "MLOps & Prozesse"
  },
  {
    "frage": "13. Welches Tool wird im Kurs primär für das Experiment-Tracking und die Modell-Verwaltung (Model Registry) verwendet?",
    "optionen": [
      "TensorBoard",
      "Weights & Biases",
      "MLflow",
      "DVC"
    ],
    "loesung": 2,
    "erklaerung": "MLflow wird im Kurs als zentrales MLOps-Tool verwendet, um Experimente (Parameter, Metriken) zu tracken und trainierte Modelle in einer 'Model Registry' zu versionieren und zu verwalten.",
    "gewichtung": 3,
    "thema": "MLOps & Tools"
  },
  {
    "frage": "14. Was ist der Hauptzweck einer `requirements.txt`-Datei?",
    "optionen": [
      "Sie enthält den Python-Code für die Anwendung.",
      "Sie listet alle Python-Bibliotheken und deren Versionen auf, die für ein Projekt benötigt werden.",
      "Sie beschreibt die Architektur eines Neuronalen Netzes.",
      "Sie enthält die Trainingsdaten für ein Machine-Learning-Modell."
    ],
    "loesung": 1,
    "erklaerung": "Die `requirements.txt` Datei ermöglicht es, eine Python-Umgebung mit genau den richtigen Abhängigkeiten zu reproduzieren, was für die Zusammenarbeit und das Deployment entscheidend ist. Man installiert sie mit `pip install -r requirements.txt`.",
    "gewichtung": 1,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "15. Welcher Python-Befehl wird verwendet, um eine Spalte namens 'Alter' aus einem Pandas DataFrame 'df' auszuwählen?",
    "optionen": [
      "df.get('Alter')",
      "df['Alter']",
      "df.column('Alter')",
      "df.select('Alter')"
    ],
    "loesung": 1,
    "erklaerung": "Die Standardmethode, um auf eine Spalte in einem Pandas DataFrame zuzugreifen, ist die Verwendung der eckigen Klammern mit dem Spaltennamen als String: df['Alter'].",
    "gewichtung": 1,
    "thema": "Pandas"
  },
  {
    "frage": "16. Was ist der Unterschied zwischen `st.write()` und `st.dataframe()` in Streamlit?",
    "optionen": [
      "Es gibt keinen Unterschied, beide machen das Gleiche.",
      "`st.write()` kann nur Text anzeigen, `st.dataframe()` nur Tabellen.",
      "`st.write()` ist ein 'magischer' Befehl, der viele Datentypen (inkl. DataFrames) anzeigen kann, während `st.dataframe()` eine interaktive Tabelle speziell für DataFrames rendert.",
      "`st.dataframe()` ist veraltet und sollte nicht mehr verwendet werden."
    ],
    "loesung": 2,
    "erklaerung": "`st.write()` ist ein Allzweck-Befehl. Wenn man ihm einen Pandas DataFrame übergibt, zeigt er eine statische Tabelle an. `st.dataframe()` hingegen rendert eine interaktive Tabelle mit Sortier- und Filterfunktionen.",
    "gewichtung": 2,
    "thema": "Streamlit"
  },
  {
    "frage": "17. Was beschreibt der Begriff 'Overfitting' im Machine Learning?",
    "optionen": [
      "Das Modell ist zu einfach und kann die Muster in den Daten nicht lernen.",
      "Das Modell lernt die Trainingsdaten 'auswendig', inklusive des Rauschens, und generalisiert schlecht auf neue Daten.",
      "Das Training des Modells dauert zu lange.",
      "Das Modell wurde mit zu wenigen Daten trainiert."
    ],
    "loesung": 1,
    "erklaerung": "Overfitting tritt auf, wenn ein Modell zu komplex ist im Verhältnis zur Datenmenge. Es passt sich perfekt an die Trainingsdaten an, verliert aber die Fähigkeit, auf ungesehenen Daten gute Vorhersagen zu machen.",
    "gewichtung": 2,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "18. Welcher der folgenden Filter wird typischerweise zur Kantenerkennung in der Bildverarbeitung verwendet?",
    "optionen": [
      "Mean-Filter (Blur)",
      "Median-Filter",
      "Gauß-Filter",
      "Sobel-Filter"
    ],
    "loesung": 3,
    "erklaerung": "Der Sobel-Filter ist ein klassischer Kantenerkennungs-Operator, der die Ableitung (den Gradienten) der Bildintensität berechnet, um Kanten hervorzuheben. Blur-Filter hingegen glätten das Bild.",
    "gewichtung": 2,
    "thema": "Computer Vision"
  },
  {
    "frage": "19. Was ist der Hauptvorteil der Verwendung von Transformer-Modellen (wie BERT oder GPT) gegenüber LSTMs für NLP-Aufgaben?",
    "optionen": [
      "Transformer sind einfacher zu implementieren.",
      "Transformer können stark parallelisiert werden, was das Training auf GPUs erheblich beschleunigt.",
      "Transformer benötigen weniger Speicher.",
      "Transformer können nur für Textgenerierung verwendet werden."
    ],
    "loesung": 1,
    "erklaerung": "LSTMs verarbeiten Sequenzen Wort für Wort, was die Parallelisierung erschwert. Transformer verarbeiten alle Wörter einer Sequenz gleichzeitig mithilfe des 'Attention'-Mechanismus, was sie ideal für moderne Hardware wie GPUs und TPUs macht.",
    "gewichtung": 3,
    "thema": "Natural Language Processing"
  },
  {
    "frage": "20. Was ist der Zweck eines `Dockerfile`?",
    "optionen": [
      "Es ist ein Python-Skript zum Trainieren von ML-Modellen.",
      "Es ist eine Konfigurationsdatei für Jupyter Notebooks.",
      "Es ist eine Textdatei, die die Anweisungen zum Bauen eines Docker-Images enthält.",
      "Es ist eine Log-Datei, die alle Docker-Befehle aufzeichnet."
    ],
    "loesung": 2,
    "erklaerung": "Ein Dockerfile ist wie ein Rezept. Es listet alle Schritte auf, die notwendig sind, um eine lauffähige Umgebung für eine Anwendung zu erstellen, inklusive Basis-Image, Abhängigkeiten und Startbefehlen.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "21. Welches Argument wird bei `train_test_split` von Scikit-learn verwendet, um sicherzustellen, dass die Klassenverteilung in Trainings- und Testset gleich bleibt?",
    "optionen": [
      "shuffle=True",
      "stratify=y",
      "balance=True",
      "keep_distribution=True"
    ],
    "loesung": 1,
    "erklaerung": "Das `stratify`-Argument sorgt für eine geschichtete Aufteilung. Wenn man ihm die Label-Variable `y` übergibt, stellt es sicher, dass der prozentuale Anteil jeder Klasse in Trainings- und Testdaten dem des Gesamtdatensatzes entspricht.",
    "gewichtung": 3,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "22. Was ist der Zweck des 'Pooling'-Layers in einem CNN?",
    "optionen": [
      "Die Anzahl der Features (Filter) zu erhöhen.",
      "Die räumliche Dimension der Feature Maps zu reduzieren (Downsampling).",
      "Dem Bild Rauschen hinzuzufügen, um Overfitting zu vermeiden.",
      "Die Farben des Bildes zu normalisieren."
    ],
    "loesung": 1,
    "erklaerung": "Pooling (z.B. Max-Pooling) reduziert die Höhe und Breite der Feature Maps. Dies verringert die Anzahl der Parameter und den Rechenaufwand in nachfolgenden Schichten und macht das Modell robuster gegenüber kleinen Verschiebungen im Bild.",
    "gewichtung": 2,
    "thema": "Computer Vision"
  },
  {
    "frage": "23. Welches Python-Tool wird im Kurs verwendet, um ML-Modelle als REST API bereitzustellen?",
    "optionen": [
      "Streamlit",
      "Flask",
      "Django",
      "FastAPI"
    ],
    "loesung": 3,
    "erklaerung": "FastAPI ist ein modernes, schnelles Web-Framework für Python, das sich hervorragend für die Erstellung von performanten APIs eignet, insbesondere für das Servieren von ML-Modellen.",
    "gewichtung": 2,
    "thema": "MLOps & Deployment"
  },
  {
    "frage": "24. Was ist der Unterschied zwischen `Accuracy` und `Precision` als Metrik?",
    "optionen": [
      "Es gibt keinen Unterschied.",
      "Accuracy misst den Anteil aller korrekten Vorhersagen, während Precision den Anteil der korrekten positiven Vorhersagen an allen positiven Vorhersagen misst.",
      "Precision ist immer höher als Accuracy.",
      "Accuracy wird für Regression verwendet, Precision für Klassifikation."
    ],
    "loesung": 1,
    "erklaerung": "Accuracy = (TP+TN)/(TP+TN+FP+FN). Precision = TP/(TP+FP). Precision ist wichtig, wenn die Kosten für 'False Positives' hoch sind (z.B. Spam-Filter, der wichtige E-Mails fälschlicherweise als Spam markiert).",
    "gewichtung": 3,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "25. Wie kann man in Streamlit interaktive Widgets wie Schieberegler oder Buttons in einer Seitenleiste platzieren?",
    "optionen": [
      "Man kann Widgets nicht in einer Seitenleiste platzieren.",
      "Indem man den Befehl `st.sidebar()` verwendet.",
      "Indem man den Befehlen das Präfix `st.sidebar.` voranstellt (z.B. `st.sidebar.slider(...)`).",
      "Durch die CSS-Eigenschaft `position: sidebar;`."
    ],
    "loesung": 2,
    "erklaerung": "Jeder Streamlit-Befehl, dem `st.sidebar.` vorangestellt wird, rendert das entsprechende Element in der Seitenleiste anstatt im Hauptbereich der App.",
    "gewichtung": 1,
    "thema": "Streamlit"
  },
  {
    "frage": "26. Was ist ein 'Hyperparameter'?",
    "optionen": [
      "Ein Gewicht oder Bias, das während des Trainings gelernt wird.",
      "Ein Parameter, der vor dem Trainingsprozess festgelegt wird und diesen steuert (z.B. Lernrate, Anzahl der Layer).",
      "Ein Maß für die Leistung des Modells auf dem Testdatensatz.",
      "Die Ausgabe der Verlustfunktion nach einer Trainingsepoche."
    ],
    "loesung": 1,
    "erklaerung": "Hyperparameter sind die 'Stellschrauben' eines Modells, die nicht durch das Training gelernt, sondern vom Entwickler festgelegt werden. Die Suche nach den optimalen Hyperparametern ist ein wichtiger Teil des ML-Prozesses.",
    "gewichtung": 1,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "27. Welcher Befehl wird in einem Dockerfile verwendet, um die notwendigen Python-Pakete zu installieren?",
    "optionen": [
      "INSTALL requirements.txt",
      "RUN pip install -r requirements.txt",
      "EXECUTE pip install -r requirements.txt",
      "ADD requirements.txt"
    ],
    "loesung": 1,
    "erklaerung": "Der `RUN`-Befehl führt Shell-Kommandos innerhalb des Docker-Images aus. `pip install -r requirements.txt` ist der Standardbefehl, um alle in der `requirements.txt`-Datei gelisteten Pakete zu installieren.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "28. Was ist der Zweck der `GlobalAveragePooling2D`-Schicht in einem CNN?",
    "optionen": [
      "Sie vergrößert die Feature Maps.",
      "Sie ersetzt die `Flatten`-Schicht und reduziert die Anzahl der Parameter drastisch, indem sie den Mittelwert jeder Feature Map berechnet.",
      "Sie führt eine Faltungsoperation über das gesamte Bild durch.",
      "Sie normalisiert die Pixelwerte des Eingabebildes."
    ],
    "loesung": 1,
    "erklaerung": "Anstatt die Feature Maps zu 'flatten' (was zu sehr vielen Parametern führt), berechnet Global Average Pooling den Durchschnitt jeder einzelnen Feature Map. Das Ergebnis ist ein Vektor, der direkt an die Dense-Layer weitergegeben werden kann, was das Modell oft robuster gegen Overfitting macht.",
    "gewichtung": 3,
    "thema": "Computer Vision"
  },
  {
    "frage": "29. Welches Problem löst der 'Attention'-Mechanismus in Transformer-Modellen?",
    "optionen": [
      "Das 'Vanishing Gradient'-Problem in tiefen Netzwerken.",
      "Die Schwierigkeit von RNNs/LSTMs, Langzeitabhängigkeiten in langen Sequenzen zu lernen.",
      "Die hohe Anzahl an Parametern in CNNs.",
      "Die Notwendigkeit, Daten vor dem Training zu normalisieren."
    ],
    "loesung": 1,
    "erklaerung": "Der Attention-Mechanismus erlaubt es dem Modell, für jedes Wort in einer Sequenz die Wichtigkeit jedes anderen Wortes zu bewerten. Dadurch kann es direkte Verbindungen zwischen weit entfernten Wörtern herstellen, ein Problem, mit dem rekurrente Architekturen (RNNs) zu kämpfen haben.",
    "gewichtung": 3,
    "thema": "Natural Language Processing"
  },
  {
    "frage": "30. Was ist der Hauptvorteil von `docker-compose` gegenüber einzelnen `docker run`-Befehlen?",
    "optionen": [
      "`docker-compose` ist schneller im Bauen von Images.",
      "`docker-compose` kann mehrere voneinander abhängige Container (Services) mit einer einzigen Konfigurationsdatei und einem einzigen Befehl verwalten und starten.",
      "`docker-compose` benötigt weniger Speicher.",
      "`docker-compose` ist nur für Webserver geeignet."
    ],
    "loesung": 1,
    "erklaerung": "`docker-compose` ist ein Orchestrierungstool. Es ermöglicht die Definition einer Multi-Container-Anwendung (z.B. eine Web-App, eine Datenbank und ein Caching-Service) in einer `docker-compose.yml`-Datei und deren gemeinsame Verwaltung.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "31. Welche Python-Bibliothek wird hauptsächlich für die Erstellung von interaktiven Web-Dashboards im Kurs verwendet?",
    "optionen": [
      "Flask",
      "Django",
      "Streamlit",
      "Plotly"
    ],
    "loesung": 2,
    "erklaerung": "Streamlit ist das zentrale Framework im Kurs, um schnell und einfach interaktive Web-Anwendungen und Dashboards für Data-Science- und ML-Projekte zu erstellen.",
    "gewichtung": 1,
    "thema": "Streamlit"
  },
  {
    "frage": "32. Was ist der Zweck der `fit()`-Methode bei einem Scikit-learn Modell?",
    "optionen": [
      "Sie macht Vorhersagen auf neuen Daten.",
      "Sie evaluiert die Genauigkeit des Modells.",
      "Sie trainiert das Modell mit den Trainingsdaten.",
      "Sie speichert das trainierte Modell auf der Festplatte."
    ],
    "loesung": 2,
    "erklaerung": "Die `fit(X_train, y_train)`-Methode ist der zentrale Schritt im Trainingsprozess, bei dem das Modell die Muster und Zusammenhänge aus den Trainingsdaten lernt.",
    "gewichtung": 1,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "33. Welcher der 'Big 3' Algorithmen ist ein distanzbasierter Algorithmus?",
    "optionen": [
      "Decision Tree",
      "K-Means Clustering",
      "K-Nearest Neighbors (KNN)",
      "Random Forest"
    ],
    "loesung": 2,
    "erklaerung": "KNN klassifiziert einen neuen Datenpunkt basierend auf der Mehrheitsklasse seiner 'k' nächsten Nachbarn. Die 'Nähe' wird dabei durch ein Distanzmaß (z.B. Euklidischer Abstand) bestimmt.",
    "gewichtung": 2,
    "thema": "Machine Learning Algorithmen"
  },
  {
    "frage": "34. Was ist eine 'Feature Map' im Kontext von CNNs?",
    "optionen": [
      "Eine Landkarte, die die wichtigsten Features eines Landes zeigt.",
      "Die Ausgabe eines Filters nach der Faltungsoperation, die die Aktivierung eines bestimmten Merkmals an verschiedenen Stellen im Bild anzeigt.",
      "Eine Liste aller Features, die für das Training verwendet werden.",
      "Ein Diagramm, das die Wichtigkeit der verschiedenen Features vergleicht."
    ],
    "loesung": 1,
    "erklaerung": "Jeder Filter in einer Convolutional-Schicht erzeugt eine Feature Map. Diese Karte zeigt, wo im Bild das vom Filter gesuchte Muster (z.B. eine vertikale Kante, ein Auge) gefunden wurde.",
    "gewichtung": 2,
    "thema": "Computer Vision"
  },
  {
    "frage": "35. Was ist der Zweck der `requirements.cloud.txt` Datei im `07_Deployment_Portfolio` Ordner?",
    "optionen": [
      "Sie enthält spezielle Anforderungen für das Training in der Cloud.",
      "Sie listet alle Python-Pakete auf, die für das Deployment der Streamlit-Apps auf Streamlit Cloud benötigt werden.",
      "Sie ist eine Sicherungskopie der normalen `requirements.txt`.",
      "Sie enthält die Zugangsdaten für die Cloud-Plattform."
    ],
    "loesung": 1,
    "erklaerung": "Deployment-Plattformen wie Streamlit Cloud benötigen eine `requirements.txt`-Datei, um zu wissen, welche Pakete für die Ausführung der App installiert werden müssen. Die `requirements.cloud.txt` ist speziell für diesen Zweck optimiert.",
    "gewichtung": 2,
    "thema": "MLOps & Deployment"
  },
  {
    "frage": "36. Welcher Datentyp wird in Python verwendet, um eine unveränderliche Liste von Elementen zu speichern?",
    "optionen": [
      "list",
      "dict",
      "set",
      "tuple"
    ],
    "loesung": 3,
    "erklaerung": "Ein Tupel (`tuple`) ist ähnlich wie eine Liste, aber seine Elemente können nach der Erstellung nicht mehr geändert, hinzugefügt oder entfernt werden. Dies macht es nützlich für Daten, die konstant bleiben sollen.",
    "gewichtung": 1,
    "thema": "Python Grundlagen"
  },
  {
    "frage": "37. Was ist der Unterschied zwischen `iloc` und `loc` in Pandas?",
    "optionen": [
      "`loc` wird für die Auswahl nach Label (Index-Name, Spalten-Name) verwendet, `iloc` für die Auswahl nach Position (Integer-Index).",
      "`iloc` ist schneller als `loc`.",
      "`loc` kann nur Zeilen auswählen, `iloc` nur Spalten.",
      "Es gibt keinen funktionalen Unterschied."
    ],
    "loesung": 0,
    "erklaerung": "`loc` ist label-basiert, z.B. `df.loc[0, 'Alter']`. `iloc` ist integer-positions-basiert, z.B. `df.iloc[0, 1]`. Die Verwendung des falschen Indexers führt oft zu Fehlern.",
    "gewichtung": 3,
    "thema": "Pandas"
  },
  {
    "frage": "38. Was ist der 'Vanishing Gradient' Problem in tiefen Neuronalen Netzen?",
    "optionen": [
      "Ein Problem, bei dem die Gradienten während der Backpropagation so groß werden, dass das Training instabil wird.",
      "Ein Problem, bei dem die Gradienten während der Backpropagation so klein werden, dass die unteren Schichten des Netzwerks kaum noch lernen.",
      "Ein Problem, bei dem das Netzwerk vergisst, was es in früheren Epochen gelernt hat.",
      "Ein Problem, bei dem die Aktivierungsfunktionen verschwinden."
    ],
    "loesung": 1,
    "erklaerung": "Bei der Backpropagation wird der Fehlergradient durch das Netzwerk zurückpropagiert. Bei tiefen Netzen und bestimmten Aktivierungsfunktionen (wie Sigmoid) kann dieser Gradient exponentiell kleiner werden, was das Update der Gewichte in den vorderen Schichten verhindert.",
    "gewichtung": 3,
    "thema": "Neuronale Netze"
  },
  {
    "frage": "39. Welche Technik wird verwendet, um das 'Vanishing Gradient'-Problem zu mildern?",
    "optionen": [
      "Verwendung von `Sigmoid`-Aktivierungsfunktionen.",
      "Erhöhung der Batch-Größe.",
      "Verwendung von `ReLU`-Aktivierungsfunktionen oder Residual Connections (ResNets).",
      "Verringerung der Lernrate."
    ],
    "loesung": 2,
    "erklaerung": "Die ReLU-Aktivierungsfunktion hat für positive Eingaben eine konstante Ableitung von 1, was den Gradientenfluss erleichtert. Residual Connections (in ResNets) schaffen 'Kurzschlüsse', die es dem Gradienten ermöglichen, Schichten zu überspringen.",
    "gewichtung": 3,
    "thema": "Neuronale Netze"
  },
  {
    "frage": "40. Was ist der Zweck der Datei `.gitignore` in einem Git-Repository?",
    "optionen": [
      "Sie enthält eine Liste von Befehlen, die Git ignorieren soll.",
      "Sie listet Dateien und Verzeichnisse auf, die von der Versionskontrolle ignoriert werden sollen (z.B. Log-Dateien, temporäre Dateien).",
      "Sie ist eine Konfigurationsdatei für GitHub Actions.",
      "Sie enthält eine Liste von Git-Benutzern, die ignoriert werden sollen."
    ],
    "loesung": 1,
    "erklaerung": "Die `.gitignore`-Datei ist entscheidend, um das Repository sauber zu halten, indem man verhindert, dass generierte Dateien, Abhängigkeiten (wie `node_modules`) oder sensible Informationen versehentlich committet werden.",
    "gewichtung": 1,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "41. Was ist der Unterschied zwischen einem `Conv2D`-Layer und einem `Dense`-Layer in Keras?",
    "optionen": [
      "Ein `Dense`-Layer ist nur für die Eingabeschicht, ein `Conv2D`-Layer nur für die Ausgabeschicht.",
      "In einem `Dense`-Layer ist jedes Neuron mit jedem Neuron der vorherigen Schicht verbunden, in einem `Conv2D`-Layer nur mit einer lokalen Region (rezeptives Feld).",
      "`Conv2D`-Layer haben immer mehr Parameter als `Dense`-Layer.",
      "`Dense`-Layer werden für Bilder, `Conv2D`-Layer für Text verwendet."
    ],
    "loesung": 1,
    "erklaerung": "Diese unterschiedliche Konnektivität ist der Kernunterschied. `Dense` (oder Fully-Connected) Layer lernen globale Muster, während `Conv2D`-Layer durch ihre lokalen rezeptiven Felder und das Weight Sharing lokale, räumliche Muster lernen.",
    "gewichtung": 2,
    "thema": "Deep Learning"
  },
  {
    "frage": "42. Was ist eine 'Epoche' im Kontext des Trainings von Machine-Learning-Modellen?",
    "optionen": [
      "Die Verarbeitung eines einzelnen Datenpunktes.",
      "Ein kompletter Durchlauf des Algorithmus durch den gesamten Trainingsdatensatz.",
      "Die Zeit, die für das Training eines Modells benötigt wird.",
      "Ein einzelner Schritt der Gewichtsaktualisierung."
    ],
    "loesung": 1,
    "erklaerung": "Eine Epoche ist abgeschlossen, wenn das Modell jeden Datenpunkt des Trainingsdatensatzes einmal gesehen hat. Das Training eines Modells erstreckt sich typischerweise über viele Epochen.",
    "gewichtung": 1,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "43. Welches Streamlit-Kommando wird verwendet, um einen Schieberegler für Zahlen zu erstellen?",
    "optionen": [
      "st.number_input()",
      "st.slider()",
      "st.range()",
      "st.numeric_selector()"
    ],
    "loesung": 1,
    "erklaerung": "`st.slider()` ist das spezifische Widget in Streamlit, um einen interaktiven Schieberegler zu erstellen, mit dem Benutzer einen numerischen Wert aus einem definierten Bereich auswählen können.",
    "gewichtung": 1,
    "thema": "Streamlit"
  },
  {
    "frage": "44. Was ist der Zweck der `predict()`-Methode bei einem trainierten Scikit-learn Modell?",
    "optionen": [
      "Sie trainiert das Modell neu mit neuen Daten.",
      "Sie gibt die gelernten Parameter des Modells zurück.",
      "Sie wendet das gelernte Modell auf neue, ungesehene Daten an, um Vorhersagen zu treffen.",
      "Sie berechnet die Genauigkeit des Modells auf den Trainingsdaten."
    ],
    "loesung": 2,
    "erklaerung": "Nachdem ein Modell mit `fit()` trainiert wurde, wird die `predict()`-Methode verwendet, um es auf neue Daten (z.B. das Testset) anzuwenden und die entsprechenden Vorhersagen (Klassen oder Werte) zu generieren.",
    "gewichtung": 1,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "45. Was ist der Hauptunterschied zwischen einem `Dockerfile` und einem `docker-compose.yml`?",
    "optionen": [
      "Ein `Dockerfile` baut ein einzelnes Image, während `docker-compose.yml` mehrere Container (Services) definiert und orchestriert.",
      "Ein `Dockerfile` ist für die Entwicklung, `docker-compose.yml` für die Produktion.",
      "Ein `Dockerfile` ist in Python geschrieben, `docker-compose.yml` in YAML.",
      "Es gibt keinen wesentlichen Unterschied."
    ],
    "loesung": 0,
    "erklaerung": "Ein `Dockerfile` ist die Bauanleitung für einen einzelnen Container. `docker-compose` ist ein Werkzeug, um Multi-Container-Anwendungen zu definieren und auszuführen, wobei jeder Container auf seinem eigenen `Dockerfile` basieren kann.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "46. Welcher der folgenden Algorithmen ist ein Ensemble-Modell?",
    "optionen": [
      "K-Nearest Neighbors (KNN)",
      "Decision Tree",
      "Random Forest",
      "Linear Regression"
    ],
    "loesung": 2,
    "erklaerung": "Ein Random Forest ist ein Ensemble-Modell, das aus vielen einzelnen Decision Trees besteht. Er trifft Vorhersagen, indem er die Vorhersagen der einzelnen Bäume aggregiert (z.B. durch Mehrheitsentscheid), was oft zu robusteren und genaueren Ergebnissen führt.",
    "gewichtung": 2,
    "thema": "Machine Learning Algorithmen"
  },
  {
    "frage": "47. Was ist der Zweck der `Flatten`-Schicht in einem CNN?",
    "optionen": [
      "Sie glättet das Eingabebild.",
      "Sie wandelt die mehrdimensionalen Feature Maps am Ende der Convolutional-Blöcke in einen eindimensionalen Vektor um.",
      "Sie reduziert die Anzahl der Farben im Bild.",
      "Sie führt eine Faltungsoperation durch."
    ],
    "loesung": 1,
    "erklaerung": "Nach den Convolutional- und Pooling-Layern liegen die Daten als mehrdimensionale Tensoren (Feature Maps) vor. Um sie an die nachfolgenden `Dense`-Layer (die einen Vektor als Input erwarten) übergeben zu können, muss dieser Tensor 'geglättet' oder 'plattgedrückt' werden.",
    "gewichtung": 2,
    "thema": "Computer Vision"
  },
  {
    "frage": "48. Was ist ein 'REST API'?",
    "optionen": [
      "Eine spezielle Art von Machine-Learning-Modell.",
      "Eine standardisierte Schnittstelle, die es verschiedenen Softwaresystemen ermöglicht, über das HTTP-Protokoll miteinander zu kommunizieren.",
      "Ein Tool zur Versionskontrolle von Code.",
      "Eine Datenbank für große Datenmengen."
    ],
    "loesung": 1,
    "erklaerung": "REST (Representational State Transfer) ist ein Architekturstil für verteilte Systeme. Eine REST API ermöglicht es einem Client (z.B. eine Web-App), Daten von einem Server (z.B. einem ML-Modell-Server) über Standard-HTTP-Methoden (GET, POST, etc.) anzufordern.",
    "gewichtung": 2,
    "thema": "MLOps & Deployment"
  },
  {
    "frage": "49. Welches Python-Keyword wird verwendet, um eine Funktion zu definieren?",
    "optionen": [
      "function",
      "def",
      "fun",
      "define"
    ],
    "loesung": 1,
    "erklaerung": "In Python wird das Keyword `def` verwendet, um eine neue Funktion zu deklarieren, gefolgt vom Funktionsnamen, den Parametern in Klammern und einem Doppelpunkt.",
    "gewichtung": 1,
    "thema": "Python Grundlagen"
  },
  {
    "frage": "50. Was ist der Zweck der `BatchNormalization`-Schicht in einem Neuronalen Netz?",
    "optionen": [
      "Sie erhöht die Anzahl der lernbaren Parameter.",
      "Sie normalisiert die Aktivierungen zwischen den Schichten, um das Training zu stabilisieren und zu beschleunigen.",
      "Sie ersetzt die Notwendigkeit von Aktivierungsfunktionen.",
      "Sie funktioniert nur in der ersten Schicht eines Netzwerks."
    ],
    "loesung": 1,
    "erklaerung": "Batch Normalization normalisiert die Ausgaben einer Schicht, bevor sie an die nächste weitergegeben werden. Dies wirkt dem Problem des 'Internal Covariate Shift' entgegen, erlaubt höhere Lernraten und macht das Training insgesamt stabiler und schneller.",
    "gewichtung": 3,
    "thema": "Neuronale Netze"
  },
  {
    "frage": "51. Welcher Befehl wird verwendet, um alle laufenden Docker-Container anzuzeigen?",
    "optionen": [
      "docker show all",
      "docker list",
      "docker ps",
      "docker containers"
    ],
    "loesung": 2,
    "erklaerung": "`docker ps` listet alle aktuell laufenden Container auf. Um auch gestoppte Container anzuzeigen, verwendet man `docker ps -a`.",
    "gewichtung": 1,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "52. Wie kann man in Streamlit eine Datei-Upload-Funktion erstellen?",
    "optionen": [
      "st.upload_file()",
      "st.file_uploader()",
      "st.input(type='file')",
      "st.load_file()"
    ],
    "loesung": 1,
    "erklaerung": "Das Widget `st.file_uploader()` erstellt eine Schaltfläche, mit der Benutzer Dateien von ihrem lokalen System in die Streamlit-App hochladen können, die dann z.B. mit Pandas verarbeitet werden können.",
    "gewichtung": 2,
    "thema": "Streamlit"
  },
  {
    "frage": "53. Was ist der Unterschied zwischen `pd.read_csv()` und `pd.read_excel()` in Pandas?",
    "optionen": [
      "Es gibt keinen Unterschied.",
      "`read_csv()` liest kommagetrennte Dateien, `read_excel()` liest Excel-Dateien (.xls, .xlsx).",
      "`read_excel()` ist schneller als `read_csv()`.",
      "`read_csv()` kann nur Textdateien lesen."
    ],
    "loesung": 1,
    "erklaerung": "Pandas bietet spezifische Funktionen für verschiedene Dateiformate. `pd.read_csv()` ist für CSV-Dateien optimiert, während `pd.read_excel()` die komplexere Struktur von Excel-Arbeitsmappen (inkl. verschiedener Blätter) handhaben kann.",
    "gewichtung": 1,
    "thema": "Pandas"
  },
  {
    "frage": "54. Was ist eine 'Confusion Matrix'?",
    "optionen": [
      "Eine Matrix, die die Korrelation zwischen verschiedenen Features zeigt.",
      "Eine Tabelle, die die Leistung eines Klassifikationsmodells visualisiert, indem sie die Anzahlen von True Positives, True Negatives, False Positives und False Negatives darstellt.",
      "Eine Methode zur Visualisierung von hochdimensionalen Daten.",
      "Eine Technik zur Hyperparameter-Optimierung."
    ],
    "loesung": 1,
    "erklaerung": "Die Confusion Matrix ist ein wichtiges Werkzeug zur Evaluation von Klassifikationsmodellen. Sie zeigt detailliert, welche Klassen das Modell gut unterscheidet und wo es zu Verwechslungen kommt.",
    "gewichtung": 2,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "55. Welcher der 'Big 3' Algorithmen ist am besten für die Interpretation und Erklärung von Entscheidungen geeignet?",
    "optionen": [
      "K-Means Clustering",
      "K-Nearest Neighbors (KNN)",
      "Decision Tree",
      "Alle sind gleich gut interpretierbar."
    ],
    "loesung": 2,
    "erklaerung": "Decision Trees (Entscheidungsbäume) sind von Natur aus sehr gut interpretierbar, da ihre Struktur einer Reihe von verständlichen Ja/Nein-Fragen entspricht. Man kann den Entscheidungspfad für jede Vorhersage nachvollziehen.",
    "gewichtung": 2,
    "thema": "Machine Learning Algorithmen"
  },
  {
    "frage": "56. Was ist der Zweck der `Dropout`-Schicht in einem Neuronalen Netz?",
    "optionen": [
      "Sie beschleunigt das Training, indem sie zufällig Datenpunkte auslässt.",
      "Sie ist eine Regularisierungstechnik, die Overfitting verhindert, indem sie während des Trainings zufällig einen Teil der Neuronen 'ausschaltet'.",
      "Sie fügt dem Netzwerk zusätzliche Neuronen hinzu.",
      "Sie dient als Aktivierungsfunktion."
    ],
    "loesung": 1,
    "erklaerung": "Indem in jedem Trainingsschritt zufällig Neuronen deaktiviert werden, zwingt Dropout das Netzwerk, robustere und weniger voneinander abhängige Features zu lernen. Dies wirkt Overfitting entgegen und verbessert die Generalisierungsfähigkeit.",
    "gewichtung": 3,
    "thema": "Neuronale Netze"
  },
  {
    "frage": "57. Was ist der Unterschied zwischen 'semantischer Segmentierung' und 'Instanzensegmentierung' in der Computer Vision?",
    "optionen": [
      "Es gibt keinen Unterschied.",
      "Semantische Segmentierung klassifiziert jedes Pixel im Bild, während Instanzensegmentierung zusätzlich zwischen verschiedenen Instanzen derselben Klasse unterscheidet.",
      "Instanzensegmentierung ist einfacher als semantische Segmentierung.",
      "Semantische Segmentierung verwendet CNNs, Instanzensegmentierung nicht."
    ],
    "loesung": 1,
    "erklaerung": "Beispiel: Bei einem Bild mit zwei Katzen würde die semantische Segmentierung alle Katzenpixel als 'Katze' markieren. Die Instanzensegmentierung würde sie als 'Katze 1' und 'Katze 2' unterscheiden.",
    "gewichtung": 3,
    "thema": "Computer Vision"
  },
  {
    "frage": "58. Was ist der Zweck der `fine-tuning`-Phase beim Transfer Learning?",
    "optionen": [
      "Den vortrainierten Teil des Modells komplett neu zu trainieren.",
      "Nur den neu hinzugefügten Klassifikator zu trainieren.",
      "Die Gewichte der oberen Schichten des vortrainierten Modells mit einer sehr kleinen Lernrate leicht anzupassen, um sie besser auf die neue Aufgabe zu spezialisieren.",
      "Die Anzahl der Layer im Modell zu reduzieren."
    ],
    "loesung": 2,
    "erklaerung": "Nachdem der neue Klassifikator trainiert wurde (Feature Extraction), werden einige der oberen Schichten des Basis-Modells 'aufgetaut'. Mit einer sehr kleinen Lernrate werden diese Gewichte dann vorsichtig an die Nuancen des neuen Datensatzes angepasst, ohne das wertvolle vortrainierte Wissen zu zerstören.",
    "gewichtung": 3,
    "thema": "Deep Learning"
  },
  {
    "frage": "59. Welches Hugging Face Modell wird im Kurs als Beispiel für Textgenerierung verwendet?",
    "optionen": [
      "BERT",
      "T5",
      "distilgpt2",
      "RoBERTa"
    ],
    "loesung": 2,
    "erklaerung": "Im Notebook `02_NLP_und_Text_Generation.ipynb` wird `distilgpt2`, eine kleinere und schnellere Version von GPT-2, als Beispiel für eine Textgenerierungs-Pipeline mit der Hugging Face `transformers`-Bibliothek verwendet.",
    "gewichtung": 2,
    "thema": "Natural Language Processing"
  },
  {
    "frage": "60. Was bedeutet der Begriff 'CI/CD' im Kontext von MLOps?",
    "optionen": [
      "'Continuous Integration / Continuous Deployment': Ein Satz von Praktiken zur Automatisierung des Build-, Test- und Deployment-Prozesses.",
      "'Complex Intelligence / Complex Deployment': Eine Methode für sehr komplexe Modelle.",
      "'Code Inspection / Code Delivery': Ein Werkzeug zur Code-Analyse.",
      "'Cloud Infrastructure / Cloud Database': Bezieht sich auf die verwendete Cloud-Infrastruktur."
    ],
    "loesung": 0,
    "erklaerung": "CI/CD ist ein Kernprinzip von DevOps und MLOps. Continuous Integration automatisiert das Testen bei jeder Code-Änderung, während Continuous Deployment den Prozess automatisiert, neue Versionen in die Produktion zu bringen.",
    "gewichtung": 2,
    "thema": "MLOps & Deployment"
  },
  {
    "frage": "61. Welcher Datentyp in Python wird verwendet, um Schlüssel-Wert-Paare zu speichern?",
    "optionen": [
      "list",
      "tuple",
      "set",
      "dict"
    ],
    "loesung": 3,
    "erklaerung": "Ein Dictionary (`dict`) ist eine ungeordnete Sammlung von Daten in einem Schlüssel-Wert-Format. Es ist optimiert für das schnelle Nachschlagen von Werten anhand ihrer Schlüssel.",
    "gewichtung": 1,
    "thema": "Python Grundlagen"
  },
  {
    "frage": "62. Wie kann man in Pandas alle Zeilen eines DataFrames `df` anzeigen, in denen der Wert der Spalte 'Alter' größer als 30 ist?",
    "optionen": [
      "df.filter('Alter' > 30)",
      "df[df['Alter'] > 30]",
      "df.select('Alter' > 30)",
      "df.where('Alter' > 30)"
    ],
    "loesung": 1,
    "erklaerung": "Dies wird als 'boolean indexing' oder 'boolean masking' bezeichnet. `df['Alter'] > 30` erzeugt eine Serie von `True`/`False`-Werten, die dann verwendet wird, um die entsprechenden Zeilen aus dem DataFrame zu filtern.",
    "gewichtung": 2,
    "thema": "Pandas"
  },
  {
    "frage": "63. Was ist der Zweck von `st.cache_data` in Streamlit?",
    "optionen": [
      "Es speichert die gesamte App im Browser-Cache.",
      "Es ist ein Decorator, der das Ergebnis einer Funktion zwischenspeichert. Wenn die Funktion mit denselben Argumenten erneut aufgerufen wird, wird das Ergebnis aus dem Cache geholt, anstatt die Funktion erneut auszuführen.",
      "Es komprimiert die Daten, die in der App angezeigt werden.",
      "Es löscht den Cache der App."
    ],
    "loesung": 1,
    "erklaerung": "Caching ist entscheidend für die Performance von Streamlit-Apps. Langsame Operationen wie das Laden großer Datensätze oder das Trainieren von Modellen sollten mit `@st.cache_data` oder `@st.cache_resource` versehen werden, um unnötige Neuberechnungen bei jedem App-Rerun zu vermeiden.",
    "gewichtung": 3,
    "thema": "Streamlit"
  },
  {
    "frage": "64. Was ist der Unterschied zwischen Regression und Klassifikation?",
    "optionen": [
      "Regression wird für Bilder verwendet, Klassifikation für Text.",
      "Regression sagt kontinuierliche Werte voraus (z.B. Preise), Klassifikation sagt diskrete Kategorien voraus (z.B. Spam/Nicht-Spam).",
      "Regression ist immer ein Unsupervised-Learning-Problem.",
      "Klassifikation benötigt mehr Daten als Regression."
    ],
    "loesung": 1,
    "erklaerung": "Dies ist die grundlegendste Unterscheidung bei Supervised-Learning-Problemen. Die Wahl des Modells, der Verlustfunktion und der Evaluationsmetriken hängt direkt davon ab, ob man einen numerischen Wert oder eine Kategorie vorhersagen möchte.",
    "gewichtung": 1,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "65. Warum ist die Skalierung von Features (z.B. mit `StandardScaler`) für den KNN-Algorithmus wichtig?",
    "optionen": [
      "Sie ist nicht wichtig für KNN.",
      "Sie wandelt alle Features in Ganzzahlen um.",
      "Da KNN auf Distanzmessungen basiert, würden Features mit großen Wertebereichen (z.B. Gehalt) die Distanzberechnung dominieren und Features mit kleinen Wertebereichen (z.B. Alter) irrelevant machen.",
      "Sie reduziert die Anzahl der Features."
    ],
    "loesung": 2,
    "erklaerung": "KNN ist ein distanzbasierter Algorithmus. Wenn die Features unterschiedliche Skalen haben, werden die Distanzen von den Features mit den größten Wertebereichen dominiert. Die Skalierung (z.B. auf einen Mittelwert von 0 und eine Standardabweichung von 1) stellt sicher, dass alle Features gleichberechtigt zur Distanzberechnung beitragen.",
    "gewichtung": 3,
    "thema": "Machine Learning Algorithmen"
  },
  {
    "frage": "66. Was ist ein 'Autoencoder'?",
    "optionen": [
      "Ein Supervised-Learning-Modell zur Klassifikation von Bildern.",
      "Ein Neuronales Netz, das lernt, seine eigene Eingabe zu rekonstruieren, oft über eine komprimierte Repräsentation (Bottleneck).",
      "Ein Algorithmus zur automatischen Generierung von Python-Code.",
      "Ein spezieller Typ eines Reinforcement-Learning-Agenten."
    ],
    "loesung": 1,
    "erklaerung": "Ein Autoencoder besteht aus einem Encoder, der die Eingabe in einen niedrigdimensionalen Code komprimiert, und einem Decoder, der versucht, aus diesem Code die ursprüngliche Eingabe zu rekonstruieren. Er wird für Dimensionsreduktion, Feature Learning und Anomalieerkennung verwendet.",
    "gewichtung": 3,
    "thema": "Neuronale Netze"
  },
  {
    "frage": "67. Was ist der Zweck der `padding='same'`-Einstellung in einem `Conv2D`-Layer?",
    "optionen": [
      "Sie fügt dem Bild einen zufälligen Rand hinzu.",
      "Sie stellt sicher, dass die räumliche Dimension der Ausgabe (Höhe und Breite) die gleiche ist wie die der Eingabe.",
      "Sie entfernt den Rand des Bildes.",
      "Sie verdoppelt die Größe des Bildes."
    ],
    "loesung": 1,
    "erklaerung": "Ohne Padding würde die Größe der Feature Map bei jeder Faltung kleiner werden. `padding='same'` fügt dem Rand der Eingabe implizit Nullen hinzu (Zero-Padding), sodass die Ausgabe die gleiche Höhe und Breite wie die Eingabe hat. Dies ist nützlich, um sehr tiefe Netzwerke zu bauen.",
    "gewichtung": 2,
    "thema": "Computer Vision"
  },
  {
    "frage": "68. Was ist ein 'Token' im Kontext von Natural Language Processing (NLP)?",
    "optionen": [
      "Ein spezielles Zeichen, das das Ende eines Satzes markiert.",
      "Ein einzelnes Wort, ein Teil eines Wortes (Subword) oder ein Satzzeichen, in das ein Text aufgeteilt wird.",
      "Ein Synonym für ein Wort.",
      "Ein Maß für die Komplexität eines Textes."
    ],
    "loesung": 1,
    "erklaerung": "Tokenisierung ist der erste Schritt in den meisten NLP-Pipelines. Dabei wird ein Rohtext in eine Liste von Tokens zerlegt, die dann in numerische Vektoren (Embeddings) umgewandelt werden können, die das Modell verarbeiten kann.",
    "gewichtung": 2,
    "thema": "Natural Language Processing"
  },
  {
    "frage": "69. Was ist der Zweck des `EXPOSE`-Befehls in einem Dockerfile?",
    "optionen": [
      "Er öffnet einen Port auf dem Host-System.",
      "Er teilt Docker mit, dass der Container an einem bestimmten Netzwerkport lauscht. Er veröffentlicht den Port aber nicht tatsächlich.",
      "Er installiert einen Webserver im Container.",
      "Er macht den Container im Netzwerk sichtbar."
    ],
    "loesung": 1,
    "erklaerung": "`EXPOSE` ist eine Form der Dokumentation zwischen dem Ersteller des Images und der Person, die den Container ausführt. Um den Port tatsächlich zu veröffentlichen und vom Host aus zugänglich zu machen, muss man die Option `-p` oder `-P` beim `docker run`-Befehl verwenden.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "70. Was ist der Unterschied zwischen `pip` und `conda`?",
    "optionen": [
      "`pip` ist für Python 2, `conda` für Python 3.",
      "`pip` installiert Python-Pakete in jeder Umgebung, während `conda` ein plattformübergreifender Paket- und Umgebungsmanager ist, der auch Nicht-Python-Pakete und ganze Umgebungen verwalten kann.",
      "`conda` ist schneller als `pip`.",
      "Es gibt keinen Unterschied."
    ],
    "loesung": 1,
    "erklaerung": "`pip` ist der Standard-Paketmanager für Python. `conda` ist Teil der Anaconda-Distribution und kann nicht nur Python-Pakete, sondern auch komplexe Abhängigkeiten (wie C-Bibliotheken) und isolierte Umgebungen verwalten, was es in der Data Science sehr beliebt macht.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "71. Was ist der Zweck der `groupby()`-Funktion in Pandas?",
    "optionen": [
      "Sie sortiert den DataFrame nach einer bestimmten Spalte.",
      "Sie gruppiert den DataFrame anhand einer oder mehrerer Spalten, um Aggregationsfunktionen (wie `sum()`, `mean()`) auf jede Gruppe anzuwenden.",
      "Sie wählt eine Gruppe von Zeilen aus.",
      "Sie benennt die Spalten des DataFrames um."
    ],
    "loesung": 1,
    "erklaerung": "Die `groupby()`-Operation ist ein extrem mächtiges Werkzeug für die Datenanalyse. Sie folgt dem 'Split-Apply-Combine'-Muster: Daten aufteilen, eine Funktion anwenden und die Ergebnisse wieder zusammenführen.",
    "gewichtung": 2,
    "thema": "Pandas"
  },
  {
    "frage": "72. Wie kann man in Streamlit den Inhalt auf mehrere Spalten aufteilen?",
    "optionen": [
      "Durch die Verwendung von HTML-Tabellen.",
      "Durch die Verwendung von `st.columns()`.",
      "Durch die Verwendung von `st.split()`.",
      "Das ist in Streamlit nicht möglich."
    ],
    "loesung": 1,
    "erklaerung": "Der Befehl `col1, col2 = st.columns(2)` erstellt zwei Spalten. Anschließend kann man mit `with col1:` und `with col2:` Inhalte in die jeweilige Spalte platzieren, um komplexere Layouts zu erstellen.",
    "gewichtung": 2,
    "thema": "Streamlit"
  },
  {
    "frage": "73. Was ist der Unterschied zwischen `EarlyStopping` und `ModelCheckpoint` Callbacks in Keras?",
    "optionen": [
      "Beide machen das Gleiche.",
      "`EarlyStopping` beendet das Training, wenn sich eine Metrik nicht mehr verbessert, während `ModelCheckpoint` das beste Modell während des Trainings speichert.",
      "`ModelCheckpoint` beendet das Training, `EarlyStopping` speichert das Modell.",
      "`EarlyStopping` wird für Regression verwendet, `ModelCheckpoint` für Klassifikation."
    ],
    "loesung": 1,
    "erklaerung": "Beide sind nützliche Callbacks. `EarlyStopping` verhindert Overfitting, indem es das Training abbricht, wenn z.B. der Validierungsfehler nicht mehr sinkt. `ModelCheckpoint` stellt sicher, dass man am Ende nicht ein schlechteres Modell hat, nur weil das Training zu lange lief, indem es die Version mit der besten Leistung auf dem Validierungsset speichert.",
    "gewichtung": 3,
    "thema": "Deep Learning"
  },
  {
    "frage": "74. Was ist der Zweck der `random_state`-Parameters in vielen Scikit-learn Funktionen?",
    "optionen": [
      "Er steuert die Zufälligkeit des Algorithmus, um die Ergebnisse reproduzierbar zu machen.",
      "Er setzt den Zustand des Modells auf einen zufälligen Wert.",
      "Er wählt zufällige Features für das Training aus.",
      "Er hat keine Funktion und wird ignoriert."
    ],
    "loesung": 0,
    "erklaerung": "Viele Algorithmen haben eine stochastische (zufällige) Komponente (z.B. die Initialisierung der Gewichte). Durch das Setzen von `random_state` auf einen festen Integer-Wert wird sichergestellt, dass der Zufallszahlengenerator immer im gleichen Zustand startet, was zu identischen Ergebnissen bei wiederholten Durchläufen führt.",
    "gewichtung": 1,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "75. Welcher der folgenden ist KEIN Hyperparameter eines Decision Tree?",
    "optionen": [
      "max_depth",
      "min_samples_split",
      "feature_importance",
      "criterion (gini/entropy)"
    ],
    "loesung": 2,
    "erklaerung": "`max_depth`, `min_samples_split` und `criterion` sind alles Hyperparameter, die vor dem Training festgelegt werden, um die Struktur und das Verhalten des Baumes zu steuern. `feature_importance` ist ein Attribut des trainierten Modells, das nach dem Training berechnet wird.",
    "gewichtung": 2,
    "thema": "Machine Learning Algorithmen"
  },
  {
    "frage": "76. Was ist der Unterschied zwischen einem 'Dense' Layer und einem 'Embedding' Layer in Keras?",
    "optionen": [
      "Ein `Dense`-Layer ist für die Eingabe, ein `Embedding`-Layer für die Ausgabe.",
      "Ein `Dense`-Layer führt eine Matrix-Vektor-Multiplikation durch, während ein `Embedding`-Layer eine Nachschlagetabelle für kategoriale Eingaben (wie Wörter) ist.",
      "Ein `Embedding`-Layer hat immer mehr Parameter als ein `Dense`-Layer.",
      "Es gibt keinen funktionalen Unterschied."
    ],
    "loesung": 1,
    "erklaerung": "Ein `Embedding`-Layer ist eine effiziente Methode, um hochdimensionale, dünn besetzte kategoriale Daten (wie Wörter in einem Vokabular, die als Integer repräsentiert werden) in dichte, niedrigdimensionale Vektoren umzuwandeln. Es ist im Wesentlichen eine lernbare Nachschlagetabelle, während ein `Dense`-Layer eine vollständige lineare Transformation durchführt.",
    "gewichtung": 3,
    "thema": "Natural Language Processing"
  },
  {
    "frage": "77. Was ist ein 'Volume' in Docker?",
    "optionen": [
      "Die Größe des Docker-Images.",
      "Ein Mechanismus, um Daten persistent außerhalb des Container-Dateisystems zu speichern, sodass sie auch nach dem Löschen des Containers erhalten bleiben.",
      "Ein Netzwerk-Interface für den Container.",
      "Ein Maß für die Rechenleistung, die ein Container verbraucht."
    ],
    "loesung": 1,
    "erklaerung": "Container sind standardmäßig zustandslos. Wenn ein Container entfernt wird, gehen alle darin geschriebenen Daten verloren. Volumes ermöglichen es, Daten (z.B. Datenbankdateien, Logs, hochgeladene Dateien) persistent auf dem Host-System zu speichern.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "78. Welches Diagramm eignet sich am besten, um die Beziehung zwischen zwei kontinuierlichen Variablen zu visualisieren?",
    "optionen": [
      "Balkendiagramm (Bar Chart)",
      "Kreisdiagramm (Pie Chart)",
      "Histogramm",
      "Streudiagramm (Scatter Plot)"
    ],
    "loesung": 3,
    "erklaerung": "Ein Streudiagramm plottet jeden Datenpunkt als Punkt in einem 2D-Koordinatensystem, wobei die x- und y-Positionen den Werten der beiden Variablen entsprechen. Dies macht es ideal, um Korrelationen, Cluster und Ausreißer zu erkennen.",
    "gewichtung": 1,
    "thema": "Datenvisualisierung"
  },
  {
    "frage": "79. Was ist der Zweck der `predict_proba()`-Methode bei vielen Scikit-learn Klassifikationsmodellen?",
    "optionen": [
      "Sie macht die gleiche Vorhersage wie `predict()`.",
      "Sie gibt die Wahrscheinlichkeit für jede Klasse zurück, anstatt nur die wahrscheinlichste Klasse.",
      "Sie berechnet die Wahrscheinlichkeit, dass das Modell korrekt ist.",
      "Sie ist nur für Regressionsmodelle verfügbar."
    ],
    "loesung": 1,
    "erklaerung": "Während `predict()` die 'harte' Klassenzuweisung (z.B. 0 oder 1) zurückgibt, gibt `predict_proba()` die 'weiche' Zuweisung in Form von Wahrscheinlichkeiten für jede Klasse zurück. Dies ist nützlich, um die Konfidenz des Modells zu bewerten.",
    "gewichtung": 2,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "80. Was ist der Hauptzweck der Phase 'K' (Knowledge Transfer) im QUA³CK-Modell?",
    "optionen": [
      "Das Sammeln von neuem Wissen über das Problem.",
      "Das Trainieren des Modells mit mehr Wissen.",
      "Die Überführung der Ergebnisse und des Modells in eine nutzbare Anwendung (z.B. eine Streamlit-App) und die Dokumentation des Projekts.",
      "Das Testen des Wissens der Entwickler."
    ],
    "loesung": 2,
    "erklaerung": "Die K-Phase schließt den Kreis, indem sie sicherstellt, dass die gewonnenen Erkenntnisse und das entwickelte Modell nicht nur in einem Notebook bleiben, sondern in eine Form gebracht werden, die für Endbenutzer oder andere Systeme von Nutzen ist und das Wissen für die Zukunft bewahrt.",
    "gewichtung": 2,
    "thema": "MLOps & Prozesse"
  },
  {
    "frage": "81. Was ist der Unterschied zwischen einem Python `list` und einem `set`?",
    "optionen": [
      "Listen sind geordnet und können Duplikate enthalten, Sets sind ungeordnet und enthalten nur eindeutige Elemente.",
      "Listen können nur Zahlen enthalten, Sets nur Strings.",
      "Sets sind veränderbar, Listen nicht.",
      "Es gibt keinen Unterschied."
    ],
    "loesung": 0,
    "erklaerung": "Sets sind nützlich, wenn man schnell prüfen will, ob ein Element vorhanden ist, oder wenn man Duplikate aus einer Liste entfernen möchte. Listen behalten die Reihenfolge der Elemente bei und erlauben Duplikate.",
    "gewichtung": 1,
    "thema": "Python Grundlagen"
  },
  {
    "frage": "82. Welcher Pandas-Befehl wird verwendet, um fehlende Werte (NaN) in einem DataFrame `df` mit dem Wert 0 zu füllen?",
    "optionen": [
      "df.replace(NaN, 0)",
      "df.remove_nan(0)",
      "df.fillna(0)",
      "df.set_nan(0)"
    ],
    "loesung": 2,
    "erklaerung": "Die `fillna()`-Methode ist das Standardwerkzeug in Pandas, um fehlende Werte zu behandeln. Man kann sie mit einem konstanten Wert, dem Mittelwert, dem Median oder anderen Strategien verwenden.",
    "gewichtung": 2,
    "thema": "Pandas"
  },
  {
    "frage": "83. Was ist der Zweck von `st.session_state` in Streamlit?",
    "optionen": [
      "Es speichert den Zustand der aktuellen Browser-Sitzung.",
      "Es ist eine Möglichkeit, Variablen über mehrere Reruns einer App hinweg zu speichern und beizubehalten.",
      "Es speichert die Konfiguration der Streamlit-App.",
      "Es ist eine veraltete Funktion."
    ],
    "loesung": 1,
    "erklaerung": "Streamlit führt das Skript bei jeder Interaktion neu aus. Um Informationen (wie Zähler, Benutzereingaben, Chat-Verläufe) zwischen diesen Reruns zu speichern, wird das `st.session_state`-Objekt verwendet, das wie ein Dictionary funktioniert.",
    "gewichtung": 3,
    "thema": "Streamlit"
  },
  {
    "frage": "84. Was ist der 'Curse of Dimensionality' (Fluch der Dimensionalität)?",
    "optionen": [
      "Das Phänomen, dass die Leistung von ML-Modellen mit zunehmender Anzahl von Features abnimmt.",
      "Die Tatsache, dass Daten in hochdimensionalen Räumen sehr spärlich werden und Distanzmaße ihre Aussagekraft verlieren.",
      "Die Notwendigkeit, bei hochdimensionalen Daten immer Deep Learning zu verwenden.",
      "Ein Fehler, der auftritt, wenn ein Datensatz mehr Spalten als Zeilen hat."
    ],
    "loesung": 1,
    "erklaerung": "In hochdimensionalen Räumen liegen die Datenpunkte tendenziell weit voneinander entfernt. Dies macht Algorithmen, die auf Distanzmessungen basieren (wie KNN), weniger effektiv und erfordert exponentiell mehr Daten, um den Raum abzudecken.",
    "gewichtung": 3,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "85. Was ist der Unterschied zwischen einem 'Validation Set' und einem 'Test Set'?",
    "optionen": [
      "Es gibt keinen Unterschied, die Begriffe sind austauschbar.",
      "Das Validation Set wird zum Trainieren, das Test Set zum Validieren verwendet.",
      "Das Validation Set wird zur Hyperparameter-Optimierung während der Entwicklung verwendet, das Test Set zur finalen, einmaligen Leistungsbewertung des fertigen Modells.",
      "Das Test Set ist immer größer als das Validation Set."
    ],
    "loesung": 2,
    "erklaerung": "Das Validation Set wird wiederholt während der Entwicklung verwendet, um das Modell zu justieren (z.B. für Early Stopping). Das Test Set wird idealerweise nur ein einziges Mal am Ende verwendet, um eine unverfälschte Schätzung der Leistung des finalen Modells auf völlig neuen Daten zu erhalten.",
    "gewichtung": 2,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "86. Was ist ein 'Residual Connection' (oder Skip Connection), wie sie in ResNets verwendet wird?",
    "optionen": [
      "Eine Verbindung, die die Ausgabeschicht direkt mit der Eingabeschicht verbindet.",
      "Eine Verbindung, die die Eingabe eines Blocks zur Ausgabe dieses Blocks addiert und so dem Gradienten einen 'Kurzschluss' ermöglicht.",
      "Eine Methode, um die Anzahl der Neuronen in einem Layer zu reduzieren.",
      "Eine spezielle Art von Dropout."
    ],
    "loesung": 1,
    "erklaerung": "Residual Connections ermöglichen es dem Gradienten, beim Backpropagation direkt durch einige Schichten 'hindurchzufließen'. Dies erleichtert das Training von sehr tiefen Netzwerken (z.B. mit 152 Schichten), indem es dem Vanishing-Gradient-Problem entgegenwirkt.",
    "gewichtung": 3,
    "thema": "Deep Learning"
  },
  {
    "frage": "87. Was ist der Zweck eines 'API-Keys'?",
    "optionen": [
      "Er verschlüsselt die Daten, die über die API gesendet werden.",
      "Er dient zur Authentifizierung und Autorisierung von Anfragen an eine API, um die Nutzung zu kontrollieren und zu verfolgen.",
      "Er ist der Name des Haupt-Endpoints einer API.",
      "Er beschleunigt die API-Anfragen."
    ],
    "loesung": 1,
    "erklaerung": "Viele APIs erfordern einen API-Key, um sicherzustellen, dass nur autorisierte Benutzer oder Anwendungen darauf zugreifen können. Er wird oft verwendet, um Nutzungsquoten (Rate Limiting) durchzusetzen und die Nutzung für Abrechnungszwecke zu verfolgen.",
    "gewichtung": 2,
    "thema": "MLOps & Deployment"
  },
  {
    "frage": "88. Welches Dateiformat wird oft für die Speicherung von großen, strukturierten Datensätzen empfohlen, da es spaltenorientiert und komprimiert ist?",
    "optionen": [
      "CSV",
      "JSON",
      "Parquet",
      "TXT"
    ],
    "loesung": 2,
    "erklaerung": "Parquet ist ein spaltenorientiertes Speicherformat, das für Big-Data-Workflows optimiert ist. Es ermöglicht eine sehr effiziente Kompression und Abfrage-Performance, da nur die benötigten Spalten gelesen werden müssen, was es CSV oft überlegen macht.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "89. Was ist der Hauptzweck von Reinforcement Learning (RL)?",
    "optionen": [
      "Das Finden von Mustern in ungelabelten Daten.",
      "Die Klassifikation von Daten in vordefinierte Kategorien.",
      "Das Trainieren eines Agenten, eine Sequenz von Aktionen in einer Umgebung auszuführen, um eine kumulative Belohnung zu maximieren.",
      "Die Generierung neuer, realistischer Daten."
    ],
    "loesung": 2,
    "erklaerung": "Beim RL lernt ein Agent durch Versuch und Irrtum (Trial and Error). Er interagiert mit einer Umgebung und erhält Belohnungen oder Bestrafungen für seine Aktionen, mit dem Ziel, eine Strategie (Policy) zu lernen, die die langfristige Belohnung maximiert.",
    "gewichtung": 2,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "90. Was ist der 'Exploration-Exploitation Trade-off' im Reinforcement Learning?",
    "optionen": [
      "Der Kompromiss zwischen der Verwendung von viel oder wenig Speicher.",
      "Der Kompromiss zwischen dem Ausprobieren neuer, unbekannter Aktionen (Exploration) und dem Nutzen bekannter, guter Aktionen (Exploitation).",
      "Der Kompromiss zwischen einem einfachen und einem komplexen Modell.",
      "Der Kompromiss zwischen Trainingszeit und Modellgenauigkeit."
    ],
    "loesung": 1,
    "erklaerung": "Ein RL-Agent muss entscheiden, ob er eine Aktion wählt, von der er bereits weiß, dass sie gut ist (Exploitation), oder ob er eine neue, unbekannte Aktion ausprobiert, die potenziell noch besser sein könnte (Exploration). Dies ist eine zentrale Herausforderung im RL.",
    "gewichtung": 3,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "91. Was ist der Unterschied zwischen einem `list` und einem `numpy.array`?",
    "optionen": [
      "Es gibt keinen Unterschied.",
      "Ein `numpy.array` ist für homogene, numerische Daten optimiert und ermöglicht schnelle, vektorisierte mathematische Operationen. Eine Python-`list` ist flexibler, aber langsamer.",
      "Listen können nur Strings enthalten.",
      "Numpy-Arrays sind Teil der Python-Standardbibliothek."
    ],
    "loesung": 1,
    "erklaerung": "NumPy ist die Grundlage für wissenschaftliches Rechnen in Python. Seine Array-Struktur ist in C implementiert, was Operationen auf großen Datenmengen um Größenordnungen schneller macht als mit reinen Python-Listen.",
    "gewichtung": 2,
    "thema": "Python Grundlagen"
  },
  {
    "frage": "92. Welcher Plotly Express Befehl wird verwendet, um ein interaktives Streudiagramm zu erstellen?",
    "optionen": [
      "px.bar()",
      "px.line()",
      "px.scatter()",
      "px.histogram()"
    ],
    "loesung": 2,
    "erklaerung": "`plotly.express.scatter` (üblicherweise als `px.scatter` importiert) ist die High-Level-Funktion zur Erstellung von interaktiven Streudiagrammen, die Zoom, Pan und Hover-Informationen unterstützen.",
    "gewichtung": 1,
    "thema": "Datenvisualisierung"
  },
  {
    "frage": "93. Was ist der Zweck der `__init__`-Methode in einer Python-Klasse?",
    "optionen": [
      "Sie initialisiert die Klasse selbst.",
      "Sie ist der Konstruktor der Klasse und wird aufgerufen, um ein neues Objekt (eine Instanz) zu erstellen und dessen Anfangszustand zu initialisieren.",
      "Sie zerstört das Objekt, wenn es nicht mehr benötigt wird.",
      "Sie ist eine normale Methode wie jede andere auch."
    ],
    "loesung": 1,
    "erklaerung": "Die `__init__`-Methode wird automatisch aufgerufen, wenn eine neue Instanz einer Klasse erzeugt wird. Sie wird verwendet, um die Attribute des Objekts mit den übergebenen Werten zu initialisieren.",
    "gewichtung": 2,
    "thema": "Python Grundlagen"
  },
  {
    "frage": "94. Was ist ein 'Webhook' im Kontext von CI/CD und MLOps?",
    "optionen": [
      "Ein spezieller Haken, um einen Server im Rack zu befestigen.",
      "Ein Mechanismus, der es einem System ermöglicht, ein anderes System in Echtzeit über ein Ereignis zu benachrichtigen, indem es eine HTTP-Anfrage an eine vordefinierte URL sendet.",
      "Ein Sicherheitsprotokoll für APIs.",
      "Ein Werkzeug zur Code-Formatierung."
    ],
    "loesung": 1,
    "erklaerung": "Webhooks sind der 'Klebstoff' für Automatisierung. Zum Beispiel kann GitHub einen Webhook an einen CI/CD-Server senden, wenn neuer Code gepusht wird, was dann automatisch einen neuen Build und ein neues Training auslöst.",
    "gewichtung": 3,
    "thema": "MLOps & Deployment"
  },
  {
    "frage": "95. Was ist der Unterschied zwischen einem 'Dense' und einem 'Sparse' Vektor?",
    "optionen": [
      "Dense Vektoren enthalten nur Nullen, Sparse Vektoren nur Einsen.",
      "Ein Dense Vektor speichert explizit jeden Wert, während ein Sparse Vektor nur die Nicht-Null-Werte und ihre Positionen speichert.",
      "Dense Vektoren sind immer kürzer als Sparse Vektoren.",
      "Sparse Vektoren können nicht für Machine Learning verwendet werden."
    ],
    "loesung": 1,
    "erklaerung": "Sparse Vektoren sind sehr effizient für Daten mit vielen Nullen, wie z.B. bei der One-Hot-Kodierung von großen Vokabularen im NLP. Anstatt eines riesigen Vektors mit meist Nullen speichert man nur die Positionen der Einsen.",
    "gewichtung": 2,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "96. Welches der folgenden ist ein Beispiel für eine Metrik zur Evaluation von Regressionsmodellen?",
    "optionen": [
      "Accuracy",
      "F1-Score",
      "Root Mean Squared Error (RMSE)",
      "AUC-ROC"
    ],
    "loesung": 2,
    "erklaerung": "RMSE misst die durchschnittliche quadratische Abweichung zwischen den vorhergesagten und den tatsächlichen Werten. Es ist eine der gebräuchlichsten Metriken für Regressionsprobleme. Accuracy, F1-Score und AUC-ROC sind Klassifikationsmetriken.",
    "gewichtung": 1,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "97. Was ist der Zweck der `self`-Variable in Python-Klassenmethoden?",
    "optionen": [
      "Sie ist eine globale Variable.",
      "Sie repräsentiert die Klasse selbst, nicht die Instanz.",
      "Sie ist eine Referenz auf die aktuelle Instanz der Klasse und ermöglicht den Zugriff auf deren Attribute und Methoden.",
      "Sie ist optional und kann weggelassen werden."
    ],
    "loesung": 2,
    "erklaerung": "`self` ist das erste Argument jeder Instanzmethode und wird von Python automatisch übergeben. Es ermöglicht der Methode, auf die Daten (Attribute) und anderen Methoden zuzugreifen, die zu diesem spezifischen Objekt gehören.",
    "gewichtung": 2,
    "thema": "Python Grundlagen"
  },
  {
    "frage": "98. Was ist der Hauptvorteil der Verwendung von `plotly.express` gegenüber `plotly.graph_objects`?",
    "optionen": [
      "`plotly.express` bietet mehr Anpassungsmöglichkeiten.",
      "`plotly.express` ist eine High-Level-Schnittstelle, die es ermöglicht, komplexe, interaktive Diagramme mit sehr wenig Code zu erstellen.",
      "`plotly.graph_objects` ist veraltet.",
      "`plotly.express` kann nur statische Bilder erzeugen."
    ],
    "loesung": 1,
    "erklaerung": "`plotly.express` (px) ist eine Wrapper-Bibliothek um `plotly.graph_objects`. Sie vereinfacht die Erstellung von gängigen Diagrammtypen erheblich. Für sehr komplexe oder benutzerdefinierte Visualisierungen kann man immer noch auf die detailliertere `graph_objects`-Syntax zurückgreifen.",
    "gewichtung": 2,
    "thema": "Datenvisualisierung"
  },
  {
    "frage": "99. Was ist ein 'Container Registry' wie Docker Hub oder GitHub Container Registry?",
    "optionen": [
      "Ein Ort, an dem man Docker-Container ausführt.",
      "Ein zentrales Repository zum Speichern, Verwalten und Verteilen von Docker-Images.",
      "Ein Werkzeug zur Überwachung von laufenden Containern.",
      "Eine Datenbank für Container-Metadaten."
    ],
    "loesung": 1,
    "erklaerung": "Eine Container Registry ist wie ein 'App Store' für Docker-Images. Man kann seine eigenen Images dorthin 'pushen' (hochladen) und Images von anderen 'pullen' (herunterladen), was die Zusammenarbeit und das Deployment vereinfacht.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "100. Was ist der Zweck der `main`-Block-Konstruktion `if __name__ == '__main__':` in einem Python-Skript?",
    "optionen": [
      "Sie definiert die Hauptfunktion des Skripts.",
      "Sie stellt sicher, dass der Code innerhalb des Blocks nur ausgeführt wird, wenn das Skript direkt gestartet wird, und nicht, wenn es als Modul in ein anderes Skript importiert wird.",
      "Sie ist notwendig, um globale Variablen zu deklarieren.",
      "Sie markiert den Anfang des Python-Codes."
    ],
    "loesung": 1,
    "erklaerung": "Diese Konstruktion ist eine Best Practice in Python. Sie ermöglicht es, ein Skript sowohl als eigenständiges Programm als auch als wiederverwendbares Modul zu schreiben, ohne dass beim Import sofort Code ausgeführt wird.",
    "gewichtung": 2,
    "thema": "Python Grundlagen"
  }
]