# ğŸ“ AMALEA 2025 - Data Analytics & Big Data

<div align="center">
  <img src="./kurs-logo.png" alt="AMALEA 2025 Logo" width="400">
  <br><br>
  <img src="https://img.shields.io/badge/Python-3.11%2B-blue?logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/Streamlit-App-FF4B4B?logo=streamlit&logoColor=white" alt="Streamlit">
  <img src="https://img.shields.io/badge/Docker-Enabled-2496ED?logo=docker&logoColor=white" alt="Docker">
  <img src="https://img.shields.io/badge/MLflow-Tracking-orange?logo=mlflow&logoColor=white" alt="MLflow">
  <img src="https://img.shields.io/badge/TensorFlow-2.0+-FF6F00?logo=tensorflow&logoColor=white" alt="TensorFlow">
  <img src="https://img.shields.io/badge/Hugging%20Face-Transformers-yellow?logo=huggingface&logoColor=white" alt="Hugging Face">
</div>

**Der modernisierte Data-Science-Kurs fÃ¼r Entwickler & Analysten**

> ğŸš€ **Dein Ziel:**
>
> Von Python-Basics zu **Production-Grade ML-Systemen**.
> In 7 Wochen baust du ein Portfolio aus **8 interaktiven Apps**, trainierst neuronale Netze und deployest alles in die Cloud.
>
> **Kein "Spaghetti-Code" in Notebooks, sondern sauberes Software-Engineering fÃ¼r Daten.**

## ğŸ§­ Worum es geht (KurzÃ¼berblick)

AMALEA fÃ¼hrt dich in 7 Wochen von Python-Grundlagen bis zum Deployment einer ML-API mit Dashboards. Das Repo ist in Wochen gegliedert:
- **Notebooks**: Schritt-fÃ¼r-Schritt-Anleitungen mit ErklÃ¤rungen, Ãœbungen und Executed-Versionen, damit du sofort Ergebnisse siehst.
- **Streamlit-Apps**: Interaktive Demos pro Woche, um Modelle, Visualisierungen und Workflows auszuprobieren.
- **Backend & MLOps** (W07): Eine FastAPI-Demo mit MLflow-Integration und zwei Dashboards (Monitoring, NLP), plus Compose-Stack fÃ¼r lokalen Start.
- **Requirements pro Woche**: Schlanke Installationen, damit du nur das lÃ¤dst, was du brauchst (W01â€“W03 leicht, W04 MLOps, W05 DL, W06 CV/NLP, W07 Deployment).

So nutzt du den Kurs:
1) **Woche starten:** Lies das Kernnotebook der Woche (Executed-Version als Referenz), danach selbst ausfÃ¼hren und Ãœbungen lÃ¶sen.  
2) **App ausprobieren:** Ã–ffne die passende Streamlit-App fÃ¼r schnelles Experimentieren (Features schieben, Modelle testen).  
3) **Variieren & dokumentieren:** Ã„ndere Hyperparameter/Features, logge Ergebnisse (W04/W07 mit MLflow) und notiere Learnings in kurzen Markdown-Notizen.  
4) **Deployment Ã¼ben (W07):** Starte die FastAPI + Dashboards lokal oder via Compose, spiele den Demo/Live-Schalter durch und inspiziere Requests/Responses.  
5) **Portfolio bauen:** Sammle Screenshots, kurze Beschreibungen und Metrikvergleiche; jedes Wochenziel ergibt einen Baustein fÃ¼r dein Portfolio.

## ğŸ“š PÃ¤dagogische EinfÃ¼hrung: Themen, Konzepte, Tools

AMALEA ist so gebaut, dass du in jeder Woche ein in sich geschlossenes Lernpaket aus Notebook und App bekommst. In W01â€“W02 Ã¼bst du sauberen Python-Code, den QUAÂ³CK-Prozess und Daten-Transformationen mit Pandas/NumPy; Streamlit dient als BrÃ¼cke, um sofort interaktive Ergebnisse zu sehen. W03â€“W04 vertiefen klassisches ML: Sklearn-Pipelines, Klassifikation/Regression, Ensembles, Clustering und Anomalie-Detektion. Hier lernst du, Metriken zu interpretieren, mit MLflow zu tracken und erste Versionierung von Daten/Artefakten mit DVC zu probieren. W05 fÃ¼hrt dich in Deep Learning mit Keras (Sequential/Functional API), Initialisierung/Regularisierung und leichtem Transfer Learning; du Ã¼bst, Overfitting zu erkennen und Seeds konsistent zu halten. In W06 folgen Computer Vision und NLP: CNN-Grundlagen, Augmentation, OpenCV-Feature-Extraction, Transfer-Learning-Patterns sowie eine CPU-freundliche Transformers-Demo fÃ¼r Text. W07 bÃ¼ndelt alles in einem Deployment-Modul: FastAPI fÃ¼r Inference, leichte HF-Pipelines fÃ¼r Sentiment/QA/Generate, zwei Streamlit-Dashboards fÃ¼r Monitoring/NLP und ein Compose-Stack. Durch Week-Requirements und Lockfiles bleiben Umgebungen reproduzierbar; jede Woche liefert ein lauffÃ¤higes Notebook plus App, Executed-Versionen erleichtern den Einstieg, und mit MLflow dokumentierst du deine Experimente. So entsteht Schritt fÃ¼r Schritt ein konsistentes Portfolio.

**Wie du lernen kannst**
- Folge Woche fÃ¼r Woche; jede Woche hat ein klares Ziel, ein Kernnotebook und eine kleine App.
- Starte mit den Executed-Notebooks, fÃ¼hre dann selbst aus und variiere Parameter.
- Baue jede Woche mindestens einen kleinen "Try it" Task (siehe Notebook-Ãœbungen) und dokumentiere dein Ergebnis kurz im Repo (Markdown).
- Nutze Streamlit-Apps zum schnellen Experimentieren, bevor du Code ins Notebook Ã¼bertrÃ¤gst.
- Verwende `mlflow` (W04/W07) fÃ¼r Metrik-Vergleiche und halte Seed-Konfigurationen bei.

---

## ğŸ“‹ Inhaltsverzeichnis

- [Der Tech-Stack](#-der-tech-stack-industrie-standard)
- [Deine Roadmap](#-deine-roadmap-7-wochen)
- [Quick Start](#-quick-start-docker)
- [Repository-Struktur](#-repository-struktur)
- [Kursinhalte & Portfolio](#-kursinhalte--portfolio-projekte)
- [Support](#-support)

---

##  Der Tech-Stack (Industrie-Standard)

Wir nutzen Tools, die du auch im Job finden wirst:

| Kategorie | Tools | Warum? |
|---|---|---|
| **Core** | ğŸ Python 3.11+, Pandas, NumPy | Der Gold-Standard fÃ¼r Data Science. |
| **ML & AI** | ğŸ¤– Scikit-Learn, TensorFlow, Hugging Face | Von klassischem ML bis zu modernen Transformern. |
| **App** | ğŸˆ Streamlit | Der schnellste Weg von Daten zur Web-App. |
| **Ops** | ğŸ³ Docker, MLflow | Reproduzierbare Umgebungen & Experiment-Tracking. |
| **Process** | ğŸ¦† QUAÂ³CK | Ein Framework, das Chaos in Struktur verwandelt. |

---

## ğŸ—ºï¸ Deine Roadmap (7 Wochen)

Der Kurs ist modular aufgebaut. Jede Woche liefert ein fertiges Projekt fÃ¼r dein Portfolio.

### Phase 1: Foundations & Engineering
*   **ğŸ“‚ Woche 01: Python & QUAÂ³CK**
    *   *Focus:* Clean Code, Docker-Setup, Projekt-Strukturierung.
*   **ğŸ“‚ Woche 02: Data Apps**
    *   *Focus:* Interaktive Dashboards mit Streamlit & Pandas.

### Phase 2: Machine Learning Core
*   **ğŸ“‚ Woche 03: ML Engineering**
    *   *Focus:* Scikit-Learn Pipelines, Klassifikation & Regression.
*   **ğŸ“‚ Woche 04: Advanced Algorithms**
    *   *Focus:* Ensemble Methods, Unsupervised Learning, MLOps.

### Phase 3: Deep Learning & AI
*   **ğŸ“‚ Woche 05: Neural Networks**
    *   *Focus:* TensorFlow/Keras, Deep Learning Grundlagen.
*   **ğŸ“‚ Woche 06: Computer Vision & NLP**
    *   *Focus:* CNNs, Transformer, Hugging Face.

### Phase 4: Production
*   **ğŸ“‚ Woche 07: Deployment**
    *   *Focus:* Cloud-Deployment, Model Serving, Finales Portfolio.

---

## ğŸ› ï¸ Quick Start (Docker)

### Voraussetzungen
*   [Docker Desktop](https://www.docker.com/products/docker-desktop) installiert und laufend.
*   [Git](https://git-scm.com/) installiert.

Die einfachste Art zu starten. Wir bieten zwei Varianten an:

### Option A: Full Experience (Empfohlen) ğŸ³
EnthÃ¤lt alles (inkl. TensorFlow, MLflow, Hugging Face).

```bash
# 1. Repository klonen
git clone <repository-url>
cd amalea

# 2. Services starten
docker-compose up --build

# 3. Services Ã¶ffnen
# Jupyter Lab: http://localhost:8888
# Streamlit App: http://localhost:8501
# MLflow UI:     http://localhost:5001
```

### Option B: Slim & Fast ğŸš€
Ohne schwere Deep-Learning-Bibliotheken. Schneller Download.

```bash
docker compose up -d jupyter-lab-slim streamlit-slim
```
- **Jupyter Slim**: [http://localhost:8889](http://localhost:8889)
- **Streamlit Slim**: [http://localhost:8502](http://localhost:8502)

### Option C: Einzelne Services ğŸ—ï¸
Baue nur das, was du brauchst:

```bash
# Nur Jupyter fÃ¼r Notebooks
docker build -f Dockerfile.jupyter -t amalea-jupyter .
docker run -p 8888:8888 amalea-jupyter

# Nur Streamlit fÃ¼r Apps
docker build -f Dockerfile.streamlit -t amalea-streamlit .
docker run -p 8501:8501 amalea-streamlit
```

---

## ğŸ“¦ Dependencies (nach Wochen)

Das Repository verwendet modulare Requirements-Dateien fÃ¼r effiziente Installationen:

### Core Requirements
- **`requirements-core.txt`**: Grundlegende AbhÃ¤ngigkeiten (Python, Datenbibliotheken)
- **`requirements-dev.txt`**: Entwicklungs-Tools (pytest, black, ruff, etc.)

### Wochen-spezifische Requirements
- **W01-W03**: `requirements-week01.txt` bis `requirements-week03.txt` (Python Basics, Streamlit, ML Grundlagen)
- **W04**: `requirements-week04.txt` (MLOps, MLflow, DVC)
- **W05**: `requirements-week05.txt` (TensorFlow, PyTorch)
- **W06**: `requirements-week06.txt` (OpenCV, Transformers, Computer Vision)
- **W07**: `requirements-week07.txt` (FastAPI, Deployment-Tools)

### Spezielle Setups
- **Cloud Deployment**: `requirements.cloud.txt` (optimiert fÃ¼r Streamlit Cloud)
- **Locked Versions**: `requirements-*.lock.txt` (pinned Versionen fÃ¼r Reproduzierbarkeit)

### Installation Beispiele

```bash
# Schnellstart (alles, W01â€“W07)
python -m venv .venv && source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements-week06.txt -r requirements-week07.txt

# Standard (W01â€“W03)
pip install -r requirements-week03.txt

# Mit Dev-Tools
pip install -r requirements-dev.txt

# Reproduzierbare Installation (W07)
pip install -r requirements-07.lock.txt
```

> ğŸ’¡ **Tipp**: Nutze `requirements.txt` als Alias fÃ¼r den leichten W01â€“W03-Stack. Installiere nur, was du pro Woche brauchst!

---

## â–¶ï¸ Run Cheatsheet (lokal)

### Docker Compose (Empfohlen)
```bash
# Volles Setup starten
docker-compose up --build

# Einzelne Services
docker compose up jupyter-lab-slim streamlit-slim
```

### Lokale Entwicklung
```bash
# W07 Backend starten
cd 07_Deployment_Portfolio && export PYTHONPATH=$(pwd)
uvicorn backend.main:app --host 127.0.0.1 --port 8000

# W07 Dashboards lokal
API_URL=http://127.0.0.1:8000 streamlit run 07_Deployment_Portfolio/04_streamlit_mlops_dashboard.py --server.port 8505
API_URL=http://127.0.0.1:8000 streamlit run 07_Deployment_Portfolio/05_streamlit_nlp_dashboard.py --server.port 8506

# Compose fÃ¼r W07 (API + beide Dashboards)
cd 07_Deployment_Portfolio && docker compose up --build
```

### Notebook Execution
```bash
# CV/NLP Notebooks automatisch ausfÃ¼hren
./run_cv_notebooks.sh

# Einzelne Woche starten
cd 01_Python_Grundlagen && jupyter lab
```

### Tests & QualitÃ¤t
```bash
# Alle Tests ausfÃ¼hren
pytest

# Code-QualitÃ¤t prÃ¼fen
make lint

# Formatierung
make format
```

> ğŸ”§ **Makefile**: Nutze `make install`, `make test`, `make lint` fÃ¼r automatisierte Tasks.

---

## ğŸ“ Repository-Struktur

Das Repository ist nach den Kurswochen gegliedert und enthÃ¤lt alle notwendigen Ressourcen fÃ¼r einen vollstÃ¤ndigen Data-Science-Kurs:

```text
amalea/
â”œâ”€â”€ ğŸ“‚ 01_Python_Grundlagen/           # Python Basics & QUAÂ³CK Framework
â”‚   â”œâ”€â”€ ğŸ“„ *.ipynb                     # Notebooks (inkl. executed Versionen)
â”‚   â”œâ”€â”€ ğŸ *.py                        # Streamlit Apps & Skripte
â”‚   â”œâ”€â”€ ğŸ³ Dockerfile                  # Lokaler Docker Build
â”‚   â”œâ”€â”€ ğŸ“‹ requirements.txt            # AbhÃ¤ngigkeiten
â”‚   â””â”€â”€ ğŸ“„ README.md                   # Wochen-Dokumentation
â”œâ”€â”€ ğŸ“‚ 02_Streamlit_und_Pandas/        # Interaktive Data Apps
â”œâ”€â”€ ğŸ“‚ 03_Machine_Learning/            # ML Pipelines & Modelle
â”œâ”€â”€ ğŸ“‚ 04_Advanced_Algorithms/         # Ensembles & Unsupervised Learning
â”œâ”€â”€ ğŸ“‚ 05_Neural_Networks/             # Deep Learning mit TensorFlow
â”œâ”€â”€ ğŸ“‚ 06_Computer_Vision_NLP/         # CV & NLP mit Transformers
â”œâ”€â”€ ğŸ“‚ 07_Deployment_Portfolio/        # Production Deployment & APIs
â”œâ”€â”€ ğŸ“‚ executed_notebooks/             # AusgefÃ¼hrte Notebook-Versionen
â”œâ”€â”€ ğŸ“‚ datasets/                       # Kurs-DatensÃ¤tze
â”œâ”€â”€ ğŸ“‚ Referate/                       # Studentische PrÃ¤sentationen
â”œâ”€â”€ ğŸ“‚ tests/                          # Test-Suite
â”œâ”€â”€ ğŸ“‚ BACKUP_Original_AMALEA_Notebooks/ # Backup der Originale
â”œâ”€â”€ ğŸ³ docker-compose.yml              # Multi-Service Setup
â”œâ”€â”€ ğŸ³ Dockerfile.*                    # Verschiedene Docker-Konfigurationen
â”œâ”€â”€ ğŸ“‹ requirements*.txt               # Modular requirements pro Woche
â”œâ”€â”€ ğŸ”§ Makefile                        # Build & Development Tasks
â”œâ”€â”€ âš™ï¸ pytest.ini                       # Test-Konfiguration
â”œâ”€â”€ ğŸŒ nightwatch.conf.js              # E2E Testing
â”œâ”€â”€ ğŸ“„ README.md                       # Diese Datei
â”œâ”€â”€ ğŸ“„ DEVELOPER_GUIDE.md              # Entwicklungsrichtlinien
â”œâ”€â”€ ğŸ“„ KURSBESCHREIBUNG.md             # Kurs-Details
â”œâ”€â”€ ğŸ“„ 02_Glossar_Alle_Begriffe_erklÃ¤rt.ipynb # Fachbegriffe erklÃ¤rt
â”œâ”€â”€ ğŸ“„ ML_DL_Mathematik.ipynb          # Mathematische Grundlagen
â””â”€â”€ ğŸ“„ LICENSE.md                      # Lizenz-Informationen
```

---

## ğŸ“š Kursinhalte & Portfolio-Projekte

Der Kurs ist in 7 Wochen gegliedert; alle Inhalte sind production-ready mit Executed-Notebooks, Backend und Dashboards.

| Woche | Thema |
|-------|-------|
| **01** | Python Grundlagen & QUAÂ³CK Framework |
| **02** | Streamlit & Pandas fÃ¼r interaktive Apps |
| **03** | Machine Learning Pipelines |
| **04** | Advanced Algorithms & MLOps |
| **05** | Neuronale Netze |
| **06** | Computer Vision & NLP |
| **07** | Deployment & Portfolio |

### Aktueller Stand im Repo (Auszug; production-ready)

| Woche | Kern-Notebooks | Apps / Skripte | Status |
|-------|----------------|----------------|--------|
| 01 | `00_Python_in_3_Stunden.ipynb`, `01_Docker_fÃ¼r_Data_Science.ipynb`, `02_Glossar_Alle_Begriffe_erklÃ¤rt.ipynb`, `03_QUA3CK_Prozessmodell.ipynb` | `01_Python_Grundlagen/uebungs_app.py`, `01_Python_Grundlagen/meine_erste_app.py`, `01_Python_Grundlagen/streamlit_komponenten.py` | âœ… Fertig |
| 02 | `02_Streamlit_und_Pandas/01_Erste_Streamlit_App_fixed.ipynb` | `02_Streamlit_und_Pandas/example_app.py`, `02_Streamlit_und_Pandas/hello_streamlit.py`, `02_Streamlit_und_Pandas/streamlit_komponenten.py` | âœ… Fertig |
| 03 | `03_Machine_Learning/02_ML_in_Streamlit_fixed.ipynb` | `03_Machine_Learning/iris_ml_app.py`, `03_Machine_Learning/housing_regression_app.py` | âœ… Fertig |
| 04 | `04_Advanced_Algorithms/02_MLFlow_Big3_Tracking.ipynb`, `04_Advanced_Algorithms/03_BÃ¤ume_Nachbarn_und_Clustering.ipynb` | `04_Advanced_Algorithms/streamlit_komponenten.py` | âœ… Fertig |
| 05 | `05_Neural_Networks/` (mehrere Notebooks) | `05_Neural_Networks/streamlit_komponenten.py` | âœ… Fertig |
| 06 | `06_Computer_Vision_NLP/06_01_neu_CNN_Basics.ipynb` u.a. | Runner: `run_cv_notebooks.sh` erzeugt Executed-Notebooks in `executed_notebooks/` | âœ… Fertig |
| 07 | `07_Deployment_Portfolio/` (Notebooks in `executed_notebooks/`) | FastAPI-Demo-API (`backend/main.py`), Streamlit-Dashboards, Compose-Stack | âœ… Fertig |

> â„¹ï¸ **Executed Notebooks**: Alle wichtigen Notebooks liegen in `executed_notebooks/` als HTML/PDF fÃ¼r schnelle Referenz.
> ğŸ”§ **Docker Setup**: Mehrere Dockerfile-Varianten (jupyter, streamlit, slim/full) fÃ¼r verschiedene Use-Cases.
> ğŸ“Š **MLflow Tracking**: Experiment-Logs in `mlruns/` fÃ¼r Reproduzierbarkeit.

### Portfolio-Apps (Beispiele)

**Auszug (W01â€“W07):**
1.  **Python Fundamentals Dashboard** (`01_Python_Grundlagen/uebungs_app.py`)
2.  **Streamlit Starter** (`01_Python_Grundlagen/meine_erste_app.py`)
3.  **Streamlit Pandas Demo** (`02_Streamlit_und_Pandas/example_app.py`)
4.  **Hello Streamlit Widgets** (`02_Streamlit_und_Pandas/hello_streamlit.py`)
5.  **Iris ML Playground** (`03_Machine_Learning/iris_ml_app.py`)
6.  **Housing Regression Explorer** (`03_Machine_Learning/housing_regression_app.py`)
7.  **MLOps Monitoring Dashboard** (`07_Deployment_Portfolio/04_streamlit_mlops_dashboard.py`)
8.  **NLP Demo Dashboard** (`07_Deployment_Portfolio/05_streamlit_nlp_dashboard.py`)

**Weitere Apps:** ML-, CV- und Deployment-Demos stehen in den jeweiligen Wochenordnern bereit.

---

---

## ğŸ‘¨â€ğŸ« Support & Ressourcen

### Dokumentation
- ğŸ“– **[DEVELOPER_GUIDE.md](DEVELOPER_GUIDE.md)**: Detaillierte Entwicklungsrichtlinien und Best Practices
- ğŸ“š **[KURSBESCHREIBUNG.md](KURSBESCHREIBUNG.md)**: VollstÃ¤ndige Kursbeschreibung und Lernziele
- ğŸ”§ **[Makefile](Makefile)**: Automatisierte Build- und Development-Tasks
- ğŸ§ª **Tests**: VollstÃ¤ndige Test-Suite in `tests/` mit pytest-Konfiguration

### Bei Problemen
1. **Dokumentation prÃ¼fen**: Schaue in den Wochen-Ordnern nach READMEs und der DEVELOPER_GUIDE.md
2. **Executed Notebooks**: Nutze `executed_notebooks/` fÃ¼r funktionierende Beispiele
3. **Docker Issues**: Mehrere Dockerfile-Varianten verfÃ¼gbar (slim/full)
4. **Dependencies**: Modulare requirements-Dateien fÃ¼r verschiedene Setups

### Kurs-Forum & Community
- Nutze das Kurs-Forum fÃ¼r fachliche Fragen
- Teile deine LÃ¶sungen in `Referate/` fÃ¼r andere Lernende
- Bei technischen Problemen: Issues im Repository erstellen

### ZusÃ¤tzliche Ressourcen
- ğŸ“Š **Glossar**: `02_Glossar_Alle_Begriffe_erklÃ¤rt.ipynb` - Alle Fachbegriffe erklÃ¤rt
- ğŸ”¢ **Mathematik**: `ML_DL_Mathematik.ipynb` - Mathematische Grundlagen fÃ¼r ML/DL
- ğŸ“ **Datasets**: Kurs-DatensÃ¤tze in `datasets/` fÃ¼r praktische Ãœbungen
