# ğŸš€ 07 Deployment & Portfolio

**MLOps, Modern NLP und Production-Ready Deployment (Stand: Work-in-Progress)**

## ğŸ“š Notebooks (Status)

- **01_MLOps_und_Deployment.ipynb** â€“ Kurze CPU-Demo: Iris-LogReg + Export (`artifacts/iris_lr.pkl`), Hinweis auf Serving via FastAPI.
- **02_NLP_und_Text_Generation.ipynb** â€“ Kurze CPU-Demo: einfache Sentiment-Heuristik + Stub-Text-Gen (kein groÃŸes Modell).
- **03_QUA3CK_MLOps_Integration.ipynb** â€“ QUAÂ³CK-Mini-Flow, Health/Predict-Check gegen das Backend.

### GefÃ¼hrter Ablauf
1) Backend starten (Demo oder Live) oder im Dashboard Demo-Modus lassen.
2) 01_Notebook: Mini-Train + Export (Artefakt anlegbar fÃ¼r Serving).
3) 02_Notebook: Sentiment/Gen-Stubs verstehen (schnell, CPU).
4) 03_Notebook: Health/Predict gegen API prÃ¼fen (oder Hinweis lesen, wenn API aus ist).
5) Dashboards Ã¶ffnen: erst Demo, dann Live mit `API_URL` setzen. Optional per `docker compose up --build` alles gemeinsam starten.

## ğŸš€ Streamlit Apps (Status)

- **04_streamlit_mlops_dashboard.py** â€“ Dashboard fÃ¼r Iris-Predict-API (`/health`, `/predict`). Demo-Modus integriert (simulierte Metriken), Live-Modus erwartet API.
- **05_streamlit_nlp_dashboard.py** â€“ UI fÃ¼r Text-Gen/Sentiment/Q&A (`/generate`, `/sentiment`, `/qa`). Demo-Modus integriert, Live-Modus erwartet NLP-API.

## ğŸ¯ Lernziele (Zielbild)

- ğŸ”„ **MLOps Pipeline**: Model Training bis Production Deployment (noch zu verifizieren)
- ğŸ³ **Containerization**: Docker fÃ¼r reproduzierbare ML-Services (siehe ErgÃ¤nzungen unten)
- ğŸŒ **API Development**: FastAPI fÃ¼r ML Model Serving (API wird aktuell vorausgesetzt, nicht bereitgestellt)
- ğŸ“Š **Model Monitoring**: Performance Tracking in Production (Dashboard nutzt simulierte Daten)
- ğŸ¤– **Modern NLP**: Transformer-basierte Text Processing (Backend-Service nÃ¶tig)
- ğŸš€ **Production Deployment**: Skalierbare ML-Anwendungen (Deployment-Schritte noch zu ergÃ¤nzen/kÃ¼rzen)

## ğŸ“¡ Backend (neu, leichtgewichtig)

- **FastAPI-Demo-API** unter `backend/main.py`
	- Endpunkte: `/health`, `/predict` (Iris), `/sentiment`, `/qa`, `/generate`
	- LÃ¤uft vollstÃ¤ndig CPU-basiert, keine groÃŸen Modelle.

Start (lokal):
```bash
cd 07_Deployment_Portfolio
pip install -r requirements.cloud.txt
uvicorn backend.main:app --host 0.0.0.0 --port 8000 --reload
```

Start (Docker Compose, API + beide Dashboards):
```bash
cd 07_Deployment_Portfolio
docker compose up --build
```
URLs:
- API: http://localhost:8000
- MLOps Dashboard: http://localhost:8505
- NLP Dashboard: http://localhost:8506

## ğŸ“± Streamlit Apps (Starten)

```bash
cd 07_Deployment_Portfolio
pip install -r requirements.cloud.txt

# MLOps Dashboard (Demo- oder Live-Modus wÃ¤hlbar)
streamlit run 04_streamlit_mlops_dashboard.py --server.port 8505

# NLP Dashboard (Demo- oder Live-Modus wÃ¤hlbar)
streamlit run 05_streamlit_nlp_dashboard.py --server.port 8506
```

Hinweise:
- Demo-Modus funktioniert ohne Backend; Live-Modus erwartet API auf `http://localhost:8000` (anpassbar in der Sidebar).
- Ports nach Bedarf anpassen.

## ğŸ› ï¸ Technologie-Stack (geplant/teilweise vorhanden)

### MLOps & Deployment
- **MLflow** - Experiment Tracking & Model Registry
- **FastAPI** - High-performance API Framework
- **Docker** - Containerization & Deployment
- **Streamlit** - Interactive Dashboards

### Modern NLP
- **Transformers** - State-of-the-art NLP Models
- **Hugging Face** - Pre-trained Model Hub
- **Text Generation** - GPT-style Language Models
- **Multi-task NLP** - Sentiment, Q&A, Summarization

## ğŸ—ºï¸ NÃ¤chste Schritte (Empfohlen)
- Backend: einfache Tests fÃ¼r Endpunkte ergÃ¤nzen; optional kleinere Modelle anstelle der Stubs.
- MLOps/NLP Dashboards: echte Monitoring-Metriken anbinden, Prompt-Limits/Safety weiter ausbauen.
- Falls nÃ¶tig: eigene Assets hinzufÃ¼gen; ungenutzte Beispiel-Daten/Images wurden entfernt.
